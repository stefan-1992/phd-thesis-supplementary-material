{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to calculate mean and std between the same configurations with different seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name = 'para_and_clause_results'\n",
    "\n",
    "df = pd.read_csv('data/results/' + file_name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all bleu scores to percentages\n",
    "for col in df.columns:\n",
    "    if 'bleu' in col or 'f1' in col:\n",
    "        df[col] = df[col] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Name'] = df['Name'].str.replace('train-pred', 'train-a-pred')\n",
    "# IF no-clause in Name then exp_num = 1, if calc-loss in Name then exp_num = 2, else 0\n",
    "df['exp_num'] = df['Name'].apply(lambda x: 1 if 'no-clause' in x else 2 if 'calc-loss' in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prefix_columns(group):\n",
    "    prefix_dict = {}\n",
    "    for col in group.columns:\n",
    "        if col[0] not in ['Name', 'Split']:\n",
    "            prefix_dict[(f\"{group.iloc[0]['Split'][0]}_{col[0]}\", col[1])] = group[col].tolist()[0]\n",
    "            prefix_dict[(f\"{group.iloc[1]['Split'][0]}_{col[0]}\", col[1])] = group[col].tolist()[1]\n",
    "    return pd.Series(prefix_dict)\n",
    "\n",
    "def combine_doc_random(_df):\n",
    "    # drop seeds\n",
    "    _df['Name'] = _df['Name'].str.split('_').str[:-3].str.join('_')\n",
    "\n",
    "    # Average all values for the same Name (i.e. different seeds)\n",
    "    _df = _df.groupby('Name').agg([('mean', pd.Series.mean), ('std', pd.Series.std)]).reset_index()\n",
    "\n",
    "    _df['Split'] = _df['Name'].str.split('_').str[-2:-1].str.join('_')\n",
    "    _df['Name'] = _df['Name'].str.split('_').str[:-2].str.join('_')\n",
    "\n",
    "\n",
    "    # group by Name column and apply prefix_columns function\n",
    "    combined_df = _df.groupby('Name').apply(prefix_columns).reset_index()\n",
    "\n",
    "    return combined_df.sort_values(('doc_exp_num', 'mean'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/sj47dvbx7p9dd_l626f7j3700000gn/T/ipykernel_78056/996426127.py:25: FutureWarning: ['State', 'Notes', 'User', 'Created', 'dataset', 'eval_strategy', 'evaluation_set', 'experiment', 'lr_scheduler_type', 'metric_for_best_model', 'metric_names', 'model_name', 'model_path', 'post_process', 'run_name', 'split', 'RANDOM_INPUT', 'RANDOM_INPUT_test', 'RANDOM_LABEL', 'RANDOM_LABEL_EVAL', 'RANDOM_LABEL_EVAL_test', 'RANDOM_LABEL_test', 'RANDOM_PRED', 'RANDOM_PRED_EVAL', 'RANDOM_PRED_EVAL_test', 'RANDOM_PRED_test', 'precisions', 'precisions_test', 'RANDOM_INPUT_test_oracle', 'RANDOM_LABEL_EVAL_test_oracle', 'RANDOM_LABEL_test_oracle', 'RANDOM_PRED_EVAL_test_oracle', 'RANDOM_PRED_test_oracle', 'precisions_test_oracle'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
      "  _df = _df.groupby('Name').agg([('mean', pd.Series.mean), ('std', pd.Series.std)]).reset_index()\n"
     ]
    }
   ],
   "source": [
    "combined_df = combine_doc_random(df)\n",
    "\n",
    "# round everything to one decimal place\n",
    "combined_df = combined_df.round(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>doc_lrml_f_score</th>\n",
       "      <th>random_lrml_f_score</th>\n",
       "      <th>doc_lrml_f_score</th>\n",
       "      <th>random_lrml_f_score</th>\n",
       "      <th>doc_lrml_f_score_test</th>\n",
       "      <th>random_lrml_f_score_test</th>\n",
       "      <th>doc_lrml_f_score_test</th>\n",
       "      <th>random_lrml_f_score_test</th>\n",
       "      <th>doc_bleu_test</th>\n",
       "      <th>...</th>\n",
       "      <th>doc_lrml_precision_test_oracle</th>\n",
       "      <th>random_lrml_precision_test_oracle</th>\n",
       "      <th>doc_lrml_recall_test_no_sep</th>\n",
       "      <th>random_lrml_recall_test_no_sep</th>\n",
       "      <th>doc_lrml_recall_test_no_sep</th>\n",
       "      <th>random_lrml_recall_test_no_sep</th>\n",
       "      <th>doc_lrml_recall_test_oracle</th>\n",
       "      <th>random_lrml_recall_test_oracle</th>\n",
       "      <th>doc_lrml_recall_test_oracle</th>\n",
       "      <th>random_lrml_recall_test_oracle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t5-amr_0_para-and-clause</td>\n",
       "      <td>70.9</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>56.5</td>\n",
       "      <td>70.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>61.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.5</td>\n",
       "      <td>80.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name doc_lrml_f_score random_lrml_f_score  \\\n",
       "                                        mean                mean   \n",
       "0  t5-amr_0_para-and-clause             70.9                70.5   \n",
       "\n",
       "  doc_lrml_f_score random_lrml_f_score doc_lrml_f_score_test  \\\n",
       "               std                 std                  mean   \n",
       "0              0.1                 0.7                  56.5   \n",
       "\n",
       "  random_lrml_f_score_test doc_lrml_f_score_test random_lrml_f_score_test  \\\n",
       "                      mean                   std                      std   \n",
       "0                     70.1                   0.7                      0.6   \n",
       "\n",
       "  doc_bleu_test  ... doc_lrml_precision_test_oracle  \\\n",
       "           mean  ...                            std   \n",
       "0          61.2  ...                            1.1   \n",
       "\n",
       "  random_lrml_precision_test_oracle doc_lrml_recall_test_no_sep  \\\n",
       "                                std                        mean   \n",
       "0                               0.9                         NaN   \n",
       "\n",
       "  random_lrml_recall_test_no_sep doc_lrml_recall_test_no_sep  \\\n",
       "                            mean                         std   \n",
       "0                            NaN                         NaN   \n",
       "\n",
       "  random_lrml_recall_test_no_sep doc_lrml_recall_test_oracle  \\\n",
       "                             std                        mean   \n",
       "0                            NaN                        69.5   \n",
       "\n",
       "  random_lrml_recall_test_oracle doc_lrml_recall_test_oracle  \\\n",
       "                            mean                         std   \n",
       "0                           80.8                         0.3   \n",
       "\n",
       "  random_lrml_recall_test_oracle  \n",
       "                             std  \n",
       "0                            0.5  \n",
       "\n",
       "[1 rows x 57 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics = combined_df.loc[:, (((combined_df.columns.get_level_values(0).str.contains('test') & (combined_df.columns.get_level_values(0).str.contains('bleu') | combined_df.columns.get_level_values(0).str.contains('lrml') | combined_df.columns.get_level_values(0).str.contains('f1'))) | combined_df.columns.get_level_values(0).str.contains('Name') | combined_df.columns.get_level_values(0).str.contains('Runtime') | combined_df.columns.get_level_values(0).str.contains('lrml_f')))]\n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.to_csv('data/results/' + file_name + '_combined.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
