{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.organization = os.getenv(\"OPENAI_ORGANISATION\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names_from_df(df):\n",
    "    return df['file'].split('-')[1].split('#')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lrml_utils import *\n",
    "from training_utils import compute_lrml\n",
    "\n",
    "\n",
    "# Postprocessing functions for LRML calculations\n",
    "def clean_pred(lrml, simplifications, added_spaces=True):\n",
    "    prefix = ' ' if added_spaces else ''\n",
    "\n",
    "    # postprocessing_\n",
    "    lrml = lrml.strip()\n",
    "    lrml = lrml.replace('[', '(').replace(']', ')').replace(\n",
    "        '{', '(').replace('}', ')')\n",
    "    lrml = lrml.replace(').', ')')\n",
    "    lrml = fix_then(lrml, prefix=prefix)\n",
    "    if '(' in lrml:\n",
    "        # Fix errors is postprocessing\n",
    "        lrml = reverse_loop(lrml, prefix=prefix)\n",
    "        lrml = reverse_resolve_expressions(lrml, fix_errors=True, prefix=prefix)\n",
    "        lrml = reverse_combine_rel_and_var(lrml, prefix=prefix)\n",
    "\n",
    "        lrml = reverse_move_and_or_to_data_node(lrml)\n",
    "        lrml = reverse_units(lrml, prefix=prefix)\n",
    "\n",
    "        # postprocessing\n",
    "        lrml = remove_duplicate_expressions(lrml, prefix + 'obligation')\n",
    "        lrml = remove_duplicate_expressions(lrml, prefix + 'expression')\n",
    "    return lrml\n",
    "\n",
    "def fix_then(lrml, prefix):\n",
    "    tree = parse_to_tree(lrml)\n",
    "    if len(tree.children) == 1:\n",
    "        thens = findall(tree, filter_=lambda x: ((x.name.strip() == 'then')))\n",
    "        if len(thens) > 0:\n",
    "            thens[0].parent = tree\n",
    "    return node_to_lrml(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text file\n",
    "def read_file(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        data = file.read()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from openai import OpenAIError, APIError\n",
    "import time\n",
    "\n",
    "# def ask_GPT(contextualisation, prompt, should_display=True, model=\"gpt-4-1106-preview\", temperature=0): \n",
    "def ask_GPT(contextualisation, prompt, should_display=True, model=\"gpt-3.5-turbo-0301\", temperature=0): \n",
    "    try:\n",
    "        result = openai.ChatCompletion.create(model=model,\n",
    "                                 messages=[{\"role\": \"system\", \"content\": contextualisation},\n",
    "                                           {\"role\": \"user\", \"content\": prompt}], \n",
    "                                           temperature=temperature)\n",
    "    except OpenAIError or APIError:\n",
    "        time.sleep(10)\n",
    "        result = openai.ChatCompletion.create(model=model,\n",
    "                                    messages=[{\"role\": \"system\", \"content\": contextualisation},\n",
    "                                            {\"role\": \"user\", \"content\": prompt}], \n",
    "                                            temperature=temperature)\n",
    "\n",
    "    if should_display:\n",
    "        display(Markdown(result['choices'][0]['message']['content']))\n",
    "    return result['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "df = pd.read_csv('data/lrml_ds_v8_sel.csv')\n",
    "df['spaced_lrml'] = df['lrml'].apply(tree_based_spacing)\n",
    "\n",
    "\n",
    "train_df = df.loc[df['random_split'] == 1]\n",
    "train_df['spaced_lrml'] = train_df['lrml'].apply(tree_based_spacing)\n",
    "train_df['input'] = train_df.apply(lambda j: \"Source: \" + get_file_names_from_df(j) + \" \" + j['text'] + \"\\nTarget: \", axis=1)\n",
    "\n",
    "valid_df = df.loc[df['random_split'] == 2]\n",
    "valid_df['spaced_lrml'] = valid_df['lrml'].apply(tree_based_spacing)\n",
    "valid_df['input'] = valid_df.apply(lambda j: \"Source: \" + get_file_names_from_df(j) + \" \" + j['text'] + \"\\nTarget: \", axis=1)\n",
    "valid_df['inputoutput'] = valid_df['input'] + valid_df['spaced_lrml']\n",
    "max_valid = valid_df['inputoutput'].apply(enc.encode).apply(len).max()\n",
    "\n",
    "test_df = df.loc[df['random_split'] == 3]\n",
    "test_df['spaced_lrml'] = test_df['lrml'].apply(tree_based_spacing)\n",
    "test_df['input'] = test_df.apply(lambda j: \"Source: \" + get_file_names_from_df(j) + \" \" + j['text'] + \"\\nTarget: \", axis=1)\n",
    "test_df['inputoutput'] = test_df['input'] + test_df['spaced_lrml']\n",
    "max_test = test_df['inputoutput'].apply(enc.encode).apply(len).max()\n",
    "\n",
    "\n",
    "# Document split was only tested in last experiment\n",
    "train_doc_df = df.loc[df['doc_split'] == 1]\n",
    "train_doc_df['spaced_lrml'] = train_doc_df['lrml'].apply(tree_based_spacing)\n",
    "train_doc_df['input'] = train_doc_df.apply(lambda j: \"Source: \" + get_file_names_from_df(j) + \" \" + j['text'] + \"\\nTarget: \", axis=1)\n",
    "\n",
    "test_doc_df = df.loc[df['doc_split'] == 3]\n",
    "test_doc_df['spaced_lrml'] = test_doc_df['lrml'].apply(tree_based_spacing)\n",
    "test_doc_df['input'] = test_doc_df.apply(lambda j: \"Source: \" + get_file_names_from_df(j) + \" \" + j['text'] + \"\\nTarget: \", axis=1)\n",
    "test_doc_df['inputoutput'] = test_doc_df['input'] + test_doc_df['spaced_lrml']\n",
    "max_test_doc = test_doc_df['inputoutput'].apply(enc.encode).apply(len).max()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "def calculate_ngram_overlap(text1, text2, n):\n",
    "    ngrams_text1 = set(ngrams(text1.split(), n))\n",
    "    ngrams_text2 = set(ngrams(text2.split(), n))\n",
    "    return len(ngrams_text1.intersection(ngrams_text2))\n",
    "\n",
    "def sample_rows(train_df, input_text, n_range, num_samples):\n",
    "    selected_samples = []\n",
    "    ngrams_matched = set()\n",
    "\n",
    "    while len(selected_samples) < num_samples:\n",
    "        n = random.choice(n_range)\n",
    "        train_df['overlap'] = train_df['text'].apply(lambda x: calculate_ngram_overlap(x, input_text, n))\n",
    "        sorted_df = train_df.sort_values('overlap', ascending=False)\n",
    "\n",
    "        selected_samples_df = pd.DataFrame(selected_samples, columns=train_df.columns)\n",
    "        sorted_df = sorted_df[~sorted_df['text'].isin(selected_samples_df['text'])]\n",
    "\n",
    "        for _, row in sorted_df.iterrows():\n",
    "            if ngrams_matched.intersection(row['text'].split()):\n",
    "                continue\n",
    "\n",
    "            selected_samples.append(row)\n",
    "            ngrams_matched.update(row['text'].split())\n",
    "\n",
    "            if len(selected_samples) == num_samples:\n",
    "                break\n",
    "\n",
    "        ngrams_matched = set()\n",
    "\n",
    "    return pd.DataFrame(selected_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "def get_sample_text_for_text(text, contextualisation, reversed, doc_split=False, max_length=4060):\n",
    "    # 90 is the minimum estimate of tokens for a sample\n",
    "    number_of_samples = int(max_length/90)\n",
    "    if doc_split:\n",
    "        selected_samples_df = sample_rows(train_doc_df, text, range(1,3), number_of_samples)\n",
    "    else:\n",
    "        selected_samples_df = sample_rows(train_df, text, range(1,3), number_of_samples)\n",
    "\n",
    "    return get_sample_text_for_df(selected_samples_df, contextualisation, reversed=reversed, max_length=max_length)\n",
    "\n",
    "\n",
    "# Only makes sure the length is not too long\n",
    "def get_sample_text_for_df(df, contextualisation, wandb_log=True, reversed=False, max_length=4060):\n",
    "    number_of_samples = len(df)\n",
    "    if reversed:\n",
    "        df = df[::-1]\n",
    "    # selected_samples_df = sample_rows(train_df, text, range(1,3), 35, defaults=[i for index, i in defaults.iterrows()])\n",
    "    example_random_sm = '\\n\\n'.join([\"Source: \" + get_file_names_from_df(i) + \" \" + i['text'] + \"\\nTarget: \" + i['spaced_lrml'] for index, i in df.iterrows()])\n",
    "    # Leave some space for prediction longer than the ground truth\n",
    "    while len(enc.encode(example_random_sm)) + len(enc.encode(contextualisation)) + max_valid > max_length:\n",
    "    # while len(enc.encode(example_random_sm)) + len(enc.encode(contextualisation)) + max_valid > 8000:\n",
    "        number_of_samples -= 1\n",
    "        if not reversed:\n",
    "            example_random_sm = '\\n\\n'.join([\"Source: \" + get_file_names_from_df(i) + \" \" + i['text'] + \"\\nTarget: \" + i['spaced_lrml'] for index, i in df[:number_of_samples].iterrows()])\n",
    "        else:\n",
    "            example_random_sm = '\\n\\n'.join([\"Source: \" + get_file_names_from_df(i) + \" \" + i['text'] + \"\\nTarget: \" + i['spaced_lrml'] for index, i in df[-number_of_samples:].iterrows()])\n",
    "    if wandb_log:\n",
    "        wandb.log({'num_samples': number_of_samples})\n",
    "    print(\"Number of samples: \", number_of_samples)\n",
    "    return example_random_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load('bleu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "\n",
    "# For self-reflection experiments\n",
    "def parse_number(text):\n",
    "    # Search for the pattern \"Option <number>\" in the text\n",
    "    match = re.search(r'Option (\\d+)', text)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the number from the matched pattern\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        # Return None or raise an error if no number is found\n",
    "        return None\n",
    "    \n",
    "def run_experiment(name, sample_df, contextualisation, lrml_col='spaced_lrml', everyNth=1, should_display=False, reversed=False, cot=False, step_by_step=False, valid_df=valid_df, self_reflect=False, self_reflect_df_names=[], options=False, gpt4=False, default_temperature=0, max_length=4060, doc_split=False, cot_exemplars=None):\n",
    "    with wandb.init(project='EPPM', entity='stefan_fuchs_phd', config={'run_name': name}):\n",
    "        is_first = True\n",
    "        if gpt4:\n",
    "            model=\"gpt-4-1106-preview\"\n",
    "        else:\n",
    "            model=\"gpt-3.5-turbo-0301\"\n",
    "        # Examples in System Intel\n",
    "        preds = []\n",
    "        begin = 0\n",
    "        end = len(valid_df)\n",
    "\n",
    "        name = name + \"_\" + str(len(valid_df.iloc[range(begin, end, everyNth)]))\n",
    "\n",
    "        if sample_df is not None:\n",
    "            _system_prompt = contextualisation + get_sample_text_for_df(sample_df, contextualisation, reversed=reversed, max_length=max_length)\n",
    "            sample_df.to_csv('eppm_preds/' + name + '.csv')\n",
    "        # Function defined for self-reflection experiments\n",
    "        if self_reflect:\n",
    "            validation_scores = get_validation_scores(valid_df, self_reflect_df_names)\n",
    "\n",
    "        for i in tqdm(range(begin, end, everyNth)):\n",
    "            temperature=default_temperature\n",
    "            j = valid_df.iloc[i]\n",
    "            if cot:\n",
    "                if step_by_step:\n",
    "                    prompt = j['input'].replace('Target: ', \"Let's think step by step:\\n\")\n",
    "                else:\n",
    "                    prompt = j['input'].replace('Target: ', \"\")\n",
    "            elif self_reflect: \n",
    "                # Function defined for self-reflection experiments\n",
    "                prompt = get_self_reflection_prompt(j, validation_scores[i], options)\n",
    "            else:\n",
    "                prompt = j['input']\n",
    "            if should_display:\n",
    "                print(j[lrml_col])\n",
    "            # print(j['lrml'])\n",
    "            check_condition = lambda x: 'if(' not in x\n",
    "            if cot:\n",
    "                if sample_df is not None:\n",
    "                    other_samples = get_sample_text_for_df(sample_df, contextualisation, reversed=reversed, max_length=max_length)\n",
    "                    _system_prompt = other_samples + '\\n\\n' + contextualisation\n",
    "                else:\n",
    "                    _system_prompt = contextualisation\n",
    "                if cot_exemplars:\n",
    "                    # Gets per clause exemplars through get_sample_text_for_text and appends cot_exemplars in the end\n",
    "                    _system_prompt = contextualisation + get_sample_text_for_text(j['text'], contextualisation + cot_exemplars, reversed=reversed, max_length=max_length, doc_split=doc_split) + cot_exemplars\n",
    "\n",
    "                check_condition = lambda x: 'target:' not in x.lower()\n",
    "            elif self_reflect: \n",
    "                _system_prompt = contextualisation\n",
    "                if options:\n",
    "                    check_condition = lambda x: not re.search(r'Option (\\d+)', x)\n",
    "\n",
    "            elif sample_df is None:\n",
    "                _system_prompt = contextualisation + get_sample_text_for_text(j['text'], contextualisation, reversed=reversed, max_length=max_length, doc_split=doc_split)\n",
    "\n",
    "            if is_first:\n",
    "                print(_system_prompt + '\\n\\n' + prompt)\n",
    "                is_first = False\n",
    "\n",
    "            response = ask_GPT('', _system_prompt + '\\n\\n' + prompt, should_display=should_display, model=model)            \n",
    "\n",
    "            while check_condition(response) and temperature < 2.0:\n",
    "                print('LOOP')\n",
    "                print(response)\n",
    "                print('')\n",
    "                print(_system_prompt + '\\n\\n' + prompt)\n",
    "\n",
    "                response = ask_GPT('', _system_prompt + '\\n\\n' + prompt, should_display=should_display, temperature=temperature, model=model)\n",
    "                temperature += 0.4\n",
    "            if check_condition(response):\n",
    "                print('ALTERNATIVE')\n",
    "                prompt = \"Source: \" + get_file_names_from_df(j) + \" \" + j['text'] + \"\\nTarget: \"\n",
    "                response = ask_GPT('', _system_prompt + '\\n\\n' + prompt, should_display=should_display, temperature=2.0, model=model)\n",
    "            if check_condition(response):\n",
    "                print(\"ERROR\")\n",
    "            if self_reflect and options:\n",
    "                print(response)\n",
    "                number = parse_number(response)\n",
    "                # Default to 0\n",
    "                if number is None:\n",
    "                    number = 0\n",
    "                response = list(validation_scores[i].values())[number]\n",
    "            preds.append(response)\n",
    "            \n",
    "\n",
    "        with open('eppm_preds/' + name + '.txt', 'w') as f:\n",
    "            for pred in preds:\n",
    "                f.write(pred + '\\n')\n",
    "        \n",
    "        preds =  [pred.split('Target:')[1].strip() if 'Target:' in pred else pred for pred in preds]\n",
    "\n",
    "\n",
    "        if lrml_col in valid_df.columns:\n",
    "            scores = compute_lrml(predictions=[clean_pred(pred, []) for pred in preds], references=[clean_pred(lrml, []) for lrml in valid_df[lrml_col].iloc[range(begin, end, everyNth)].tolist()], entity_weight=2, filter_empty=True)\n",
    "            scores.update(metric.compute(predictions=preds, references=valid_df[lrml_col].iloc[range(begin, end, everyNth)].tolist()))\n",
    "        else:\n",
    "            scores = {}\n",
    "            \n",
    "        wandb.run.name = name\n",
    "        wandb.log(scores)\n",
    "        wandb.log({'prompt': _system_prompt, 'exemplar_num': len(sample_df) if sample_df is not None else 0})\n",
    "\n",
    "        print(scores)\n",
    "\n",
    "        return preds, scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = train_df.loc[train_df['selected_round_2'] == 1]\n",
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected samples exeriments with different numbers of samples\n",
    "for i in reversed([1,3,5,10,15,20,25,30]):\n",
    "    new_df = new_df.sample(i)\n",
    "    exp_name = 'selected_' + str(i)\n",
    "    print(exp_name)\n",
    "    contextualisation = ''\n",
    "    preds, score = run_experiment(exp_name, new_df, contextualisation, lrml_col='spaced_lrml', everyNth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different Sets of Random Samples --- Maximum amout fitting into the token limit\n",
    "for i in range(10):\n",
    "    new_df = train_df.sample(50)\n",
    "    exp_name = 'random_' + str(i)\n",
    "    print(exp_name)\n",
    "    contextualisation = ''\n",
    "    preds, score = run_experiment(exp_name, new_df, contextualisation, lrml_col='spaced_lrml', everyNth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the following repository and navigate to it: https://github.com/rmunro/pytorch_active_learning\n",
    "cd ../../pytorch_active_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Withing pytorch_active_learning the diversity_sampling file can be found\n",
    "from diversity_sampling import DiversitySampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = DiversitySampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/stefanfuchs/Repos/MultiTaskDecoding-Exp\n"
     ]
    }
   ],
   "source": [
    "# Navigate back into the EPPM repository\n",
    "cd ../Chapter8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, j  in train_df.iterrows():\n",
    "    data.append([i, j['text'], '', 'random', 0])\n",
    "data_valid = []\n",
    "for i, j  in valid_df.iterrows():\n",
    "    data_valid.append([i, j['text'], '', 'random', 0])\n",
    "samples = sampler.get_representative_samples(data_valid, data, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = train_df.loc[[i[0] for i in samples]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'representative_sampling'\n",
    "print(exp_name)\n",
    "contextualisation = ''\n",
    "preds, score = run_experiment(exp_name, new_df, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stratified sampling by file\n",
    "indices = []\n",
    "for i in set(train_df['file']):\n",
    "    indices.extend(train_df[train_df['file'] == i].sample(min(len(train_df[train_df['file'] == i]), 2)).index.tolist())\n",
    "new_df = train_df.loc[indices]\n",
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'stratified_sampling'\n",
    "print(exp_name)\n",
    "contextualisation = ''\n",
    "new_df = new_df.sample(frac=1)\n",
    "# df = None\n",
    "preds, score = run_experiment(exp_name, new_df, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/lrml_inference/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "# all-mpnet-base-v2  bert-base-nli-mean-tokens\n",
    "embedder = SentenceTransformer('all-mpnet-base-v2')\n",
    "corpus_embeddings = embedder.encode(train_df['text'].tolist())\n",
    "\n",
    "# Cluster by embedding\n",
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 40\n",
    "clustering_model = KMeans(n_clusters=num_clusters)\n",
    "clustering_model.fit(corpus_embeddings)\n",
    "cluster_assignment = clustering_model.labels_\n",
    "\n",
    "clustered_sentences = [[] for i in range(num_clusters)]\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    clustered_sentences[cluster_id].append(train_df['text'].tolist()[sentence_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching by similarity of either valit lrml to train text, or valid text to train text\n",
    "for comparison in ['text', 'lrml']:\n",
    "    search_embeddings = embedder.encode(valid_df[comparison].tolist())\n",
    "    hits = util.semantic_search(search_embeddings, corpus_embeddings, score_function=util.dot_score)\n",
    "\n",
    "    # first of each hits\n",
    "    indices = [hits[i][0]['corpus_id'] for i in range(len(hits))]\n",
    "\n",
    "    clustered_ids = [[] for i in range(num_clusters)]\n",
    "\n",
    "    for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "        clustered_ids[cluster_id].append(sentence_id)\n",
    "\n",
    "    ids = [random.choice(i) for i in clustered_ids]\n",
    "    new_df = train_df.iloc[ids]\n",
    "    len(new_df)\n",
    "\n",
    "    new_df = train_df.iloc[list(set(indices))].sample(frac=1)\n",
    "\n",
    "    # LRML clustering\n",
    "    exp_name = 'semantic_clustering_'+ comparison\n",
    "    print(exp_name)\n",
    "    contextualisation = ''\n",
    "    preds, score = run_experiment(exp_name, new_df, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override method to use semantic retrieval for per clause sampling\n",
    "def get_sample_text_for_text(text, reversed):\n",
    "    number_of_samples = 45\n",
    "    search_embeddings = embedder.encode([text])\n",
    "    hits = util.semantic_search(search_embeddings, corpus_embeddings, score_function=util.dot_score, top_k=number_of_samples)\n",
    "    indices = [i['corpus_id'] for i in hits[0]]\n",
    "    selected_samples_df = train_df.iloc[list(set(indices))]\n",
    "    return get_sample_text_for_df(selected_samples_df, reversed=reversed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRML per clause with semantic search\n",
    "reversed_options = [True, False]\n",
    "\n",
    "for reversed in reversed_options:\n",
    "    exp_name = 'perclause_semantic_search'\n",
    "    if reversed:\n",
    "        exp_name += '_reversed'\n",
    "    print(exp_name)\n",
    "    contextualisation = ''\n",
    "    # per clause triggered through df being None\n",
    "    preds, score = run_experiment(exp_name, None, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=reversed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revert back to n-gram based per clause sampling\n",
    "def get_sample_text_for_text(text, contextualisation, reversed, doc_split=False, max_length=4060):\n",
    "    # 90 is the minimum estimate of tokens for a sample\n",
    "    number_of_samples = int(max_length/90)\n",
    "    if doc_split:\n",
    "        selected_samples_df = sample_rows(train_doc_df, text, range(1,3), number_of_samples)\n",
    "    else:\n",
    "        selected_samples_df = sample_rows(train_df, text, range(1,3), number_of_samples)\n",
    "\n",
    "    return get_sample_text_for_df(selected_samples_df, contextualisation, reversed=reversed, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-gram based per clause sampling\n",
    "for reversed in reversed_options:\n",
    "    exp_name = 'perclause'\n",
    "    if reversed:\n",
    "        exp_name += '_reversed'\n",
    "    print(exp_name)\n",
    "    contextualisation = ''\n",
    "    # per clause triggered through df being None\n",
    "    preds, score = run_experiment(exp_name, None, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=reversed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per clause sampling with GPT-4\n",
    "\n",
    "# exp_name = 'perclause_reversed_gpt4_8000'\n",
    "exp_name = 'perclause_reversed_gpt4'\n",
    "print(exp_name)\n",
    "contextualisation = ''\n",
    "preds, score = run_experiment(exp_name, None, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=True, gpt4=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextualising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Contextualisation experiments with 10 and 30 samples\n",
    "names = ['intro', 'spec', 'important', 'references', 'full']\n",
    "num_samples = [10, 30]\n",
    "for num in num_samples:\n",
    "    new_df = pd.read_csv('eppm_preds/selected_' + str(num) + '_71.csv')\n",
    "\n",
    "    for name in names:\n",
    "        exp_name = 'prompts/context_' + name + '_' + str(num)\n",
    "        print(exp_name)\n",
    "        contextualisation = read_file('prompts/prompt_eppm_' + name + '.txt')\n",
    "        preds, score = run_experiment(exp_name, new_df, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=False, gpt4=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run per clause experiments for intro and full contextualisation\n",
    "names = ['intro', 'full']\n",
    "# New df results in the per clause sampling strategy\n",
    "new_df = None\n",
    "\n",
    "for name in names:\n",
    "    exp_name = 'context_' + name + '_perclause_reverse'\n",
    "    print(exp_name)\n",
    "    contextualisation = read_file('prompts/prompt_eppm_' + name + '.txt')\n",
    "    preds, score = run_experiment(exp_name, new_df, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2354, 2033)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot = read_file('prompts/prompt_eppm_CoT.txt')\n",
    "cot2 = read_file('prompts/prompt_eppm_CoT_align.txt')\n",
    "len(enc.encode(cot)), len(enc.encode(cot2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['CoT', 'CoT_align', 'CoT_full_align']\n",
    "\n",
    "new_df = None\n",
    "\n",
    "for name in names:\n",
    "    exp_name = 'context_' + name \n",
    "    print(exp_name)\n",
    "    contextualisation = read_file('prompts/prompt_eppm_' + name + '.txt')\n",
    "\n",
    "    preds, score = run_experiment(exp_name, new_df, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=False, cot=True, step_by_step=False, should_display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare df for additional samples\n",
    "\n",
    "used_df = pd.read_csv('eppm_preds/selected_10_71.csv')\n",
    "rest_df = pd.read_csv('eppm_preds/selected_max30_71.csv')[:30]\n",
    "\n",
    "# Remove all used samples from rest_df\n",
    "rest_df = rest_df[~rest_df['text'].isin(used_df['text'])]\n",
    "len(rest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['CoT', 'CoT_5']\n",
    "\n",
    "new_df = rest_df\n",
    "\n",
    "for name in names:\n",
    "    exp_name = 'context_' + name + '_addsamples'\n",
    "    print(exp_name)\n",
    "    contextualisation = read_file('prompts/prompt_eppm_' + name + '.txt')\n",
    "\n",
    "    preds, score = run_experiment(exp_name, new_df, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=False, cot=True, step_by_step=True, should_display=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can use the predictions saved in the files to get the samples for valid_df\n",
    "# For example Per Clause samples/Selective/Random?\n",
    "# For training of this process I'll use the best performing 10 training samples and generate 5 options with different random samples + Intro Sentence?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Time Code\n",
    "\n",
    "# Make predictions with random samples for the 10 selected samples\n",
    "\n",
    "# _df = pd.read_csv('eppm_preds/selected_10_71.csv')\n",
    "# # train_df without _df\n",
    "# _train_df = train_df[~train_df['text'].isin(_df['text'])]\n",
    "# _df['input'] = _df.apply(lambda j: \"Source: \" + get_file_names_from_df(j) + \" \" + j['text'] + \"\\nTarget: \", axis=1)\n",
    "\n",
    "\n",
    "# # Random\n",
    "# for i in range(3):\n",
    "#     new_df = _train_df.sample(50)\n",
    "#     exp_name = 'random_for_train_10_' + str(i)\n",
    "#     print(exp_name)\n",
    "#     contextualisation = ''\n",
    "#     preds, score = run_experiment(exp_name, new_df, contextualisation, lrml_col='spaced_lrml', everyNth=1, valid_df=_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/sj47dvbx7p9dd_l626f7j3700000gn/T/ipykernel_79821/4221800476.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dfs = [pd.read_csv('eppm_preds/random_for_train_10_' + str(i) + '_10.txt', sep=';;;', header=None) for i in range(3)]\n",
      "/var/folders/nh/sj47dvbx7p9dd_l626f7j3700000gn/T/ipykernel_79821/4221800476.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dfs = [pd.read_csv('eppm_preds/random_for_train_10_' + str(i) + '_10.txt', sep=';;;', header=None) for i in range(3)]\n",
      "/var/folders/nh/sj47dvbx7p9dd_l626f7j3700000gn/T/ipykernel_79821/4221800476.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dfs = [pd.read_csv('eppm_preds/random_for_train_10_' + str(i) + '_10.txt', sep=';;;', header=None) for i in range(3)]\n"
     ]
    }
   ],
   "source": [
    "# Load the sample for those predictions No Separator (imitated by ;;;) - each line is one prediction\n",
    "_df = pd.read_csv('eppm_preds/selected_10_71.csv')\n",
    "dfs = [pd.read_csv('eppm_preds/random_for_train_10_' + str(i) + '_10.txt', sep=';;;', header=None) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_dict(my_dict):\n",
    "    keys = list(my_dict.keys())\n",
    "    random.shuffle(keys)\n",
    "\n",
    "    # Create a new dictionary with the shuffled keys\n",
    "    shuffled_dict = {key: my_dict[key] for key in keys}\n",
    "    return shuffled_dict\n",
    "\n",
    "# For each of the 10 samples in _df, check which of the 3 predictions in the dfs is the closest to the sample\n",
    "def score_samples(_df, dfs):\n",
    "    all_scores = []\n",
    "    for i in range(len(_df)):\n",
    "        scores = {}\n",
    "        for j in range(len(dfs)):\n",
    "            score = compute_lrml(predictions=[clean_pred(dfs[j][0][i], [])], references=[clean_pred(_df['spaced_lrml'].iloc[i], [])], entity_weight=2, filter_empty=True)['lrml_f_score']\n",
    "            # Avoid duplicates\n",
    "            while score in scores:\n",
    "                score += 0.000000001\n",
    "            # For each of the dataframes take the first and only column and the i-th row which is a prediction\n",
    "            scores[score] = dfs[j][0][i]\n",
    "        # Shufle dicts to not learn to pick the best run continuosly\n",
    "        all_scores.append(shuffle_dict(scores))\n",
    "    return all_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_index(score_dict):\n",
    "    key_list = list(score_dict)\n",
    "    index = key_list.index(max(score_dict))\n",
    "    return index\n",
    "\n",
    "def get_predicted_values(scores, options):\n",
    "    indices = list(range(len(scores)))\n",
    "    if options:\n",
    "        return '\\n'.join([str(['Option ' + str(i) + ': ' + j[1] for i, j in enumerate(scores.items())][i]) for i in indices])\n",
    "    else:\n",
    "        return '\\n'.join([str([j for i, j in scores.items()][i]) for i in indices])\n",
    "\n",
    "\n",
    "def get_self_reflection_samples(_df, dfs, choose=True, options=False):\n",
    "    all_scores = score_samples(_df, dfs)\n",
    "    if options:\n",
    "        return '\\n\\n'.join([\"Source: \" + get_file_names_from_df(i) + \" \" + i['text']  + \"\\n\" + get_predicted_values(all_scores[index], options) + \"\\nTarget: Option \" + str(get_max_index(all_scores[index])) for index, i in _df.iterrows()])\n",
    "    elif not choose:\n",
    "        return '\\n\\n'.join([\"Source: \" + get_file_names_from_df(i) + \" \" + i['text']  + \"\\n\" + get_predicted_values(all_scores[index], options) + \"\\nTarget: \" + i['spaced_lrml'] for index, i in _df.iterrows()])\n",
    "    return '\\n\\n'.join([\"Source: \" + get_file_names_from_df(i) + \" \" + i['text']  + \"\\n\" + get_predicted_values(all_scores[index], options) + \"\\nTarget: \" + all_scores[index][max(all_scores[index])] for index, i in _df.iterrows()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_scores(valid_df, df_names):\n",
    "    dfs = [pd.read_csv('eppm_preds/' + i + '.txt', sep=';;;', header=None) for i in df_names]\n",
    "    return score_samples(valid_df, dfs)\n",
    "\n",
    "def get_self_reflection_prompt(row, scores, options):\n",
    "    return \"Source: \" + get_file_names_from_df(row) + \" \" + row['text']  + \"\\n\" + get_predicted_values(scores, options) + \"\\nTarget: \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    'self_reflect_mixed': ['random_1_71', 'context_full_perclause_reverse_71', 'semantic_clustering_71'],\n",
    "    'self_reflect_best': ['perclause_reversed_71', 'context_full_perclause_reverse_71', 'context_intro_perclause_reverse_71'],\n",
    "}\n",
    "\n",
    "#  [choose, options]\n",
    "reflection_modes = { 'choose': [True, False], 'options': [False, True], 'improve': [False, False]}\n",
    "\n",
    "use_gpt4=False\n",
    "\n",
    "for name, df_names in names.items():\n",
    "    for reflection_mode_name, reflection_mode in reflection_modes.items():\n",
    "        exp_name = name + '_' + reflection_mode_name\n",
    "        print(exp_name)\n",
    "        dfs = [pd.read_csv('eppm_preds/random_for_train_10_' + str(i) + '_10.txt', sep=';;;', header=None) for i in range(3)]\n",
    "        contextualisation = get_self_reflection_samples(_df, dfs, choose=reflection_mode[0], options=reflection_mode[1])\n",
    "\n",
    "        preds, score = run_experiment(exp_name, None, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=False, cot=False, step_by_step=False, should_display=False, self_reflect=True, self_reflect_df_names=df_names, options=reflection_mode[1], gpt4=use_gpt4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreate Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_1_71 = pd.read_csv('eppm_preds/random_1_71.csv')\n",
    "# train_df without random_1_71\n",
    "_train_df = train_df[~train_df['text'].isin(random_1_71['text'][:32])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_df['inputoutput'] = _train_df['input'] + _train_df['spaced_lrml']\n",
    "max_valid = _train_df['inputoutput'].apply(enc.encode).apply(len).max()\n",
    "max_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Source: E2AS1 Parapets require a drained cavity for claddings except for vertical corrugated steel as outlined in Table 3.\\nTarget: if( and( has( parapet, cladding), not( is( cladding. material, steel)), is( steel. type, vertical corrugated))), then( obligation( and( has( parapet, drained cavity), for( drained cavity, cladding))))\\n\\nSource: D1AS1 Access Route; Single Isolated Step 1.3.2 Threshold weather stops projecting no more than 20 mm above the threshold finished surface are acceptable.\\nTarget: if( and( has( access route, single isolated step), is( single isolated step, threshold weather stop), less than equal( single isolated step. height, 20 mm), above( single isolated step. height, threshold finished surface))), then( permission( has( access route, single isolated step)))\\n\\nSource: E2AS1 For slatted decks, a minimum gap of 12 mm shall be provided between the exterior wall and the adjacent decking slat.\\nTarget: if( is( deck, slatted)), then( obligation( and( adjacent( deck. slat, wall), is( wall. type, exterior), in between( gap, and( wall, slat)), greater than equal( gap, 12 mm))))\\n\\nSource: E2AS1 Metal cappings installed over parapets and enclosed balustrades, shall be as outlined in Paragraphs 6.0 and 7.4, and comply with the following requirements: a) Tops of cappings shall be free of any penetrations, b) Slope of top shall be 5° (1:12) minimum, c) The cover at the sides of the capping shall be in accordance with Table 7, d) All cappings shall have drip edges. e) Cappings shall be separated from underlying timber by roof underlay as shown in Figure 10.\\nTarget: if( and( is( capping. material, metal), above( capping. installation, or( parapet, balustrade)), is( balustrade, enclosed))), then( obligation( and( as per( capping, and( nzbc e2as1 6.0, nzbc e2as1 7.4)), define( top of( capping), x0), not( has( x0, penetration)), greater than equal( x0.slope, 5 deg), has( capping. side, cover), as per( cover, nzbc e2as1 t7), has( capping, drip edge), has( roof, underlay), in between( underlay, and( capping, timber)), below( timber, capping), as per( underlay, nzbc e2as1 f10))))\\n\\nSource: CAS2 C1-C6 Protection from Fire; It covers buildings or parts of buildings where people: Are unable to self-evacuate without assistance through requiring special care or treatment, or they are restrained, or their liberties are restricted (SI).\\nTarget: if( or( is( building. activity, or( care, detention)), is( building. risk group, si), and( has( building, part), or( is( part. activity, or( care, detention)), is( part. risk group, si))))), then( apply to( nzbc cas2, and( building, part)))\\n\\nSource: E2AS1 9.0 Wall Claddings; 9.1.3 Bottom of cladding; Clearances shall be measured to: b) The top surface of any adjacent sloped or horizontal apron flashing.\\nTarget: if( has( wall cladding. bottom, clearance)), then( obligation( and( adjacent( flashing, wall cladding), is( flashing. type, apron), is( flashing, or( sloped, horizontal)), has( flashing, top surface), towards( clearance. measurement, top surface))))\\n\\nSource: G13AS2 Drainage 3.3.1 All gully traps shall have (see Figures 2 and 3): A minimum outlet pipe diameter of 100 mm.\\nTarget: if( exist( gully trap)), then( obligation( and( has( gully trap, outlet pipe), greater than equal( outlet pipe. diameter, 100 mm))))\\n\\nSource: E2AS1 8.4 Profiled Metal Roof Cladding 8.4.3.3 Aluminium; Aluminium for the manufacture of profiled aluminium roofing shall comply with AS/NZS 1734, and be a minimum: a) Base metal thickness (BMT) of 0.7 mm, b) 5000 series.\\nTarget: if( and( is( roof cladding. type, profiled metal), is( roof cladding. material, aluminium))), then( obligation( and( comply with( cladding. material, nzs 1734), greater than equal( aluminium. base metal thickness, 0.7 mm), greater than equal( aluminium. grade, 5000 series))))\\n\\nSource: G13AS2 Where a disused drain is being reinstated, the disused drain shall be tested to verify that the drain is sound.\\nTarget: if( is( drain, and( disused, reinstated))), then( obligation( test( drain, soundness)))\\n\\nSource: G13AS1 5.6.1 The discharge stack vent, if also acting as a drain vent pipe shall have a diameter of not less than 80 mm.\\nTarget: if( for( ventilation, and( discharge stack, drain ventilation pipe))), then( obligation( greater than equal( ventilation. diameter, 80 mm)))\\n\\nSource: G14VM1 1.8.1 Vehicle access areas for the collection of industrial liquid waste shall: a) Comply with NZBC D1 Access Routes.\\nTarget: if( and( for( vehicle access area, collection), is( collection. type, industrial liquid waste))), then( obligation( comply with( vehicle access area. area, nzbc d1)))\\n\\nSource: E2AS1 8.4 Profiled Metal Roof Cladding; Fixings shall: Include sealing washers of: ii) profiled washer and EPDM washer where required to allow for expansion of the profiled metal roof cladding.\\nTarget: if( and( is( roof cladding. type, profiled metal), has( roof cladding, fixing), requires( roof cladding, expansion allowance))), then( obligation( and( include( fixing, sealing washer), is( sealing washer. type, and( profiled washer, epdm washer)))))\\n\\nSource: E2AS1 Moisture contained in the building structure at completion of construction shall not be permitted to damage the building elements.\\nTarget: if( and( is( building. construction, completed), include( building. structure, moisture))), then( obligation( and( not( has( building. element, damage)), by( damage, moisture))))\\n\\nSource: G13AS2 Drainage 3.3.2 Gully trap which shall: Be installed so that surcharge cannot enter into or under buildings.\\nTarget: if( exist( gully trap)), then( obligation( and( not( into( gully trap. surcharge, building)), not( below( gully trap. surcharge, building)))))\\n\\nSource: E2AS1 For the catchment area of the roof above the penetration as shown in Figure 22, the roof length shall be limited to: i) for profiled metal roofing, Table 17 ii) for other roof claddings, the areas shown in Table 9.\\nTarget: if( and( has( roof, penetration), above( roof. catchment area, penetration), as per( roof. catchment area, nzbc e2as1 f22))), then( obligation( or( and( is( roof. type, profiled metal), as per( roof. length, nzbc e2as1 t17)), and( not( is( roof. type, profiled metal)), as per( roof. length, nzbc e2as1 t9)))))\\n\\nSource: G14VM1 1.4.1 Collection facilities shall be located: To ensure that spillage from storage tanks or ponds can be safely contained.\\nTarget: if( exist( collection facility)), then( obligation( not( has( collection facility. location, spillage containment))))\\n\\nSource: G14AS1 1.2.1 Discharge to the sewer without pre-treatment – Where the network utility operator accepts the discharge of industrial liquid waste to a sewer without pre-treatment, the disposal system shall comply with Acceptable Solution G13/AS2.\\nTarget: if( and( for( disposal system, industrial liquid waste), is( disposal system. disposal method, discharge), accept( network utility operator, discharge), into( discharge, sewer), not( has( industrial liquid waste, treatment)))), then( obligation( comply with( disposal system, nzbc g13as2)))\\n\\nSource: E2AS1 Use 304 or 316 stainless steel fixings for corrosion zones B, C or hot dip galvanised fixings at 450 g/m2 for Zone B and Zone C.\\nTarget: if( and( is( corrosion zone, or( b, c)), for( fixing, corrosion zone))), then( obligation( or( and( is( fixing. material, stainless steel), is( stainless steel. grade, or( 304, 306))), and( is( fixing. material, hot dip galvanized), is( fixing. weight, 450 g/m2)))))\\n\\nSource: B1AS1 2.1.3 NZS 4229; Grade 500E welded steel mesh; Where Grade 500E welded steel mesh is specified, it shall meet the requirements of Paragraph 14.0 in B1/VM1.\\nTarget: if( is( welded steel mesh. grade, 500e)), then( obligation( comply with( welded steel mesh, nzbc b1vm1 14)))\\n\\nSource: B1AS3 1.7.9 Where zinc coating of components is required it shall be no less than 300 g/m2 in accordance with AS 1397.\\nTarget: if( requires( component, zinc coating)), then( obligation( and( greater than equal( zinc coating. density, 300 g/m2), as per( zinc coating. density, as 1397))))\\n\\nSource: G13AS2 3.1.1 To reduce the risk of blockages, the foul water drainage system shall: a) Have a simple layout that incorporates the least number of changes of direction, b) Use bends having a radius of the practical maximum, and c) Be laid only in straight lines between bends or junctions (both horizontally and vertically).\\nTarget: if( exist( foul water drain)), then( obligation( and( is( foul water drain. layout, simple), is( layout. change in direction, minimum), define( foul water drain. bend, x0), is( x0.radius, practical maximum), in between( pipe, and( bend, junction)), is( pipe, straight))))\\n\\nSource: CAS2 2.2.1 Fire safety system types, as defined in Table 2.2, shall be provided throughout firecells and be as specified in: Table 2.2c for risk groups WB and WS.\\nTarget: if( is( firecell. risk group, or( wb, ws))), then( obligation( as per( firecell. fire safety system, nzbc cas2 t2.2.c)))\\n\\nSource: E1AS1 3.4.1 Minimum acceptable gradients for surface water drains are given in Table 2.\\nTarget: if( is( drain. type, surface water)), then( obligation( and( greater than equal( drain. gradient, value), as per( value, nzbc e1as1 t2))))\\n\\nSource: G12AS1 Water supply system 3.4.5 The selection of the appropriate backflow protection for the cross connection hazard is given in Table 2.\\nTarget: if( has( water supply system, cross connection hazard)), then( obligation( as per( water supply system. backflow protection, nzbc g12as1 t2)))\\n\\nSource: E2AS1 All roof-to-wall junctions shall be made weathertight by using an apron flashing as outlined in Paragraph 4.6.1.1, and shown in Figure 7, that: a) Provides a minimum lap under the wall cladding of 75 mm in accordance with Table 7.\\nTarget: if( is( junction. type, roof to wall)), then( obligation( and( is( junction, weathertight), has( junction, flashing), is( flashing. type, apron), as per( flashing, and( nzbc e2as1 4.6.1.1, nzbc e2as1 t7)), has( flashing, lap), below( lap, wall cladding), greater than equal( lap. size, 75 mm), as per( lap, nzbc e2as1 t7))))\\n\\nSource: G1AS1 1.1.2 WC pans and basins are required in any building where people: a) live or are accommodated.\\nTarget: if( is( building. activity, or( living, accomodation))), then( and( has( building, wc pan), has( building, basin)))\\n\\nSource: G14VM1 1.7.1 Separate systems shall be provided to convey and store industrial liquid wastes that require different treatment and/or disposal methods.\\nTarget: if( or( is( compare( industrial liquid wastes. treatment method), different), is( compare( industrial liquid wastes. disposal method), different))), then( loop( for each( industrial liquid wastes), obligation( and( is( industrial liquid waste. conveying system, separate), is( industrial liquid waste. storage system, separate)))))\\n\\nSource: G13AS1 Sanitary Plumbing 1.0.2 The solution does not include: The conveyance of industrial liquid wastes, chemical or toxic wastes and other wastes which cannot be discharged to a sewer without pretreatment.\\nTarget: if( or( for( sanitary plumbing, or( industrial liquid waste, chemical waste, toxic waste)), and( for( sanitary plumbing, waste), towards( waste. discharge, sewer), requires( waste. discharge, pretreatment)))), then( not( apply to( nzbc g13as1, sanitary plumbing)))\\n\\nSource: G12AS2 5.0.1 Solar water heaters must be installed in accordance with the requirements of AS/NZS 3500 Part 4, unless modified by this Acceptable Solution.\\nTarget: if( exist( solar water heater)), then( obligation( or( comply with( solar water heater. installation, nzs 3500 4), by( nzs 3500 4.modification, nzbc g12as2))))\\n\\nSource: E2AS1 Exposed bottom edges of flashings shall be folded to a kick-out or a bird's beak as shown in Figure 5.\\nTarget: if( and( has( flashing. bottom edge, exposure))), then( obligation( and( is( flashing. bottom edge, or( kick out, bird beak)), as per( flashing. bottom edge, nzbc e2as1 f5))))\\n\\nSource: B1AS3 1.1.3 Size; The width (measured along the building line) and depth (measured perpendicular to the building line) shall not exceed: For a concrete or precast pumice concrete chimney stack - 1200 mm wide x 700 mm deep.\\nTarget: if( is( chimney stack. material, or( concrete, precast pumice concrete))), then( obligation( and( define( chimney stack. width, x0), is( x0.measurement, along building line), define( chimney stack. depth, x1), is( x1.measurement, perpendicular building line), less than equal( x0, 1200 mm), less than equal( x1, 700 mm))))\\n\\nSource: G13AS2 4.2.2 Branch drain vents shall be sized in accordance with Table 6 in G13/AS1.\\nTarget: if( and( is( drain. type, branch), has( drain, ventilation))), then( obligation( comply with( ventilation. size, nzbc g13as1 t6)))\""
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intro --- Test allowed length -> 32\n",
    "contextualisation = read_file('prompts/prompt_eppm_intro.txt')\n",
    "get_sample_text_for_df(random_1_71, contextualisation, reversed=False, wandb_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['train_df'] # 75.39979152186623\n",
    "\n",
    "new_df = None\n",
    "\n",
    "for name in names:\n",
    "    exp_name = name \n",
    "    print(exp_name)\n",
    "\n",
    "    contextualisation = read_file('prompts/prompt_eppm_intro.txt')\n",
    "\n",
    "    # Only the first 32 samples of random_1_71 will be used\n",
    "    preds, score = run_experiment(exp_name, random_1_71, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=False, cot=False, step_by_step=False, should_display=False, self_reflect=False, valid_df=_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/sj47dvbx7p9dd_l626f7j3700000gn/T/ipykernel_95196/1231770670.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  prediction_df = pd.read_csv('eppm_preds/train_df_544.txt', sep=';;;', header=None)\n"
     ]
    }
   ],
   "source": [
    "prediction_df = pd.read_csv('eppm_preds/train_df_544.txt', sep=';;;', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/sj47dvbx7p9dd_l626f7j3700000gn/T/ipykernel_95196/1103726728.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _train_df['spaced_lrml'].iloc[i] = prediction_df[0][i]\n"
     ]
    }
   ],
   "source": [
    "# Map the predicted values to the training dataframe\n",
    "for i in range(len(_train_df)):\n",
    "    _train_df['spaced_lrml'].iloc[i] = prediction_df[0][i]\n",
    "_train_df.iloc['spaced_lrml'] = prediction_df[0]\n",
    "_train_df = _train_df[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the predicted values to the original dataframe\n",
    "\n",
    "# Assuming the column 'spaced_lrml' doesn't exist in the original df, create it as NaN values\n",
    "df['spaced_lrml'] = float('NaN')\n",
    "\n",
    "# Check if each row in df is present in _train_df\n",
    "mask = df.index.isin(_train_df.index)\n",
    "\n",
    "\n",
    "# Update the 'spaced_lrml' column for rows in df that are present in _train_df\n",
    "df.loc[mask, 'spaced_lrml'] = _train_df['spaced_lrml']\n",
    "\n",
    "# Calculate and update the 'spaced_lrml' column for rows in df that are not present in _train_df\n",
    "df.loc[~mask, 'spaced_lrml'] = df.loc[~mask, 'lrml'].apply(tree_based_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/lrml_ds_v8_gen_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to copyright only the 150 additional generations can be shown\n",
    "add_df = pd.read_csv('data/lrml_additional.csv')\n",
    "add_df['input'] = add_df.apply(lambda j: \"Source: \" + get_file_names_from_df(j) + \" \" + j['text'] + \"\\nTarget: \", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'additional_train'\n",
    "print(exp_name)\n",
    "contextualisation = read_file('prompts/prompt_eppm_intro.txt')\n",
    "preds, score = run_experiment(exp_name, None, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=True, valid_df=add_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_df['spaced_lrml'] = preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_df['random_split'] = 1\n",
    "add_df['doc_split'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_df.to_csv('data/lrml_additional.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload original\n",
    "df = pd.read_csv('data/lrml_ds_v8_sel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add add_df to df\n",
    "df = pd.concat([df, add_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/lrml_ds_v8_add_data_150.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload original\n",
    "df = pd.read_csv('data/lrml_ds_v8_sel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate Gpt-4 with and without context and with per clause sampling\n",
    "names = ['no','full']\n",
    "\n",
    "for name in names:\n",
    "    exp_name = 'context_' + name + '_perclause_reverse'\n",
    "    print(exp_name)\n",
    "    contextualisation = read_file('prompts/prompt_eppm_' + name + '.txt')\n",
    "    preds, score = run_experiment(exp_name, None, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=True, gpt4=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per clause sampling with longer context lenghts\n",
    "names = ['full']\n",
    "lengths = [6000, 8000]\n",
    "\n",
    "for name in names:\n",
    "    for length in lengths:\n",
    "        exp_name = 'context_' + name + '_perclause_reversed_gpt4_' + str(length)\n",
    "        print(exp_name)\n",
    "        contextualisation = read_file('prompts/prompt_eppm_' + name + '.txt')\n",
    "        preds, score = run_experiment(exp_name, None, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=True, gpt4=True, max_length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain of thought new: Context + alignment-based + step by step\n",
    "names = ['CoT_align_stepbystep']\n",
    "context = 'full'\n",
    "\n",
    "for name in names:\n",
    "    exp_name = 'context_' + context + '_' + name + '_perclause_6000'\n",
    "    print(exp_name)\n",
    "    contextualisation = read_file('prompts/prompt_eppm_' + context + '.txt')\n",
    "    cot_exemplars = read_file('prompts/prompt_eppm_' + name + '.txt')\n",
    "\n",
    "    preds, score = run_experiment(exp_name, None, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=True, cot=True, step_by_step=True, should_display=False, gpt4=True, max_length=6000, cot_exemplars=cot_exemplars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-4 Self Reflections\n",
    "names = {\n",
    "    'self_reflect_best-6000_gpt4': ['context_no_perclause_reversed_gpt4_71', 'context_full_perclause_reversed_gpt4_71', 'context_full_perclause_reversed_gpt4_6000_71']\n",
    "}\n",
    "\n",
    "#  [choose, options]\n",
    "reflection_modes = { 'choose': [True, False]}\n",
    "\n",
    "use_gpt4=False\n",
    "\n",
    "for name, df_names in names.items():\n",
    "    for reflection_mode_name, reflection_mode in reflection_modes.items():\n",
    "        exp_name = name + '_' + reflection_mode_name\n",
    "        print(exp_name)\n",
    "        dfs = [pd.read_csv('eppm_preds/random_for_train_10_' + str(i) + '_10.txt', sep=';;;', header=None) for i in range(3)]\n",
    "        contextualisation = get_self_reflection_samples(_df, dfs, choose=reflection_mode[0], options=reflection_mode[1])\n",
    "\n",
    "        preds, score = run_experiment(exp_name, None, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=False, cot=False, step_by_step=False, should_display=False, self_reflect=True, self_reflect_df_names=df_names, options=reflection_mode[1], gpt4=use_gpt4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate Gpt-4 with and without context and with per clause sampling\n",
    "names = ['no', 'intro', 'full']\n",
    "\n",
    "test_splits = [['test', False, test_df], ['doc_test', True, test_doc_df]]\n",
    "\n",
    "for name in names:\n",
    "    for test_split in test_splits:\n",
    "        exp_name = 'context_' + name + '_perclause_reverse_' + test_split[0]\n",
    "        print(exp_name)\n",
    "        contextualisation = read_file('prompts/prompt_eppm_' + name + '.txt')\n",
    "        preds, score = run_experiment(exp_name, None, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=True, gpt4=True, doc_split=test_split[1], valid_df=test_split[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per clause sampling with longer context lenghts\n",
    "names = ['full']\n",
    "lengths = [6000]\n",
    "test_splits = [['test', False, test_df], ['doc_test', True, test_doc_df]]\n",
    "\n",
    "for name in names:\n",
    "    for length in lengths:\n",
    "        for test_split in test_splits:\n",
    "            exp_name = 'context_' + name + '_perclause_reversed_gpt4_' + str(length) + '_' + test_split[0]\n",
    "            print(exp_name)\n",
    "            contextualisation = read_file('prompts/prompt_eppm_' + name + '.txt')\n",
    "            preds, score = run_experiment(exp_name, None, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=True, gpt4=True, max_length=length, doc_split=test_split[1], valid_df=test_split[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits = [\n",
    "    ['test', False, test_df, ['context_no_perclause_reversed_gpt4_test_71', 'context_full_perclause_reversed_gpt4_6000_test_71', 'context_full_perclause_reversed_gpt4_test_71']], \n",
    "    ['doc_test', True, test_doc_df, ['context_no_perclause_reversed_gpt4_doc_test_55', 'context_full_perclause_reversed_gpt4_6000_doc_test_55', 'context_full_perclause_reversed_gpt4_doc_test_55']]\n",
    "    ]\n",
    "\n",
    "#  [choose, options]\n",
    "reflection_modes = { 'choose': [True, False]}\n",
    "\n",
    "use_gpt4=False\n",
    "\n",
    "for test_split in test_splits:\n",
    "    for reflection_mode_name, reflection_mode in reflection_modes.items():\n",
    "        exp_name = 'self_reflect_best-6000_gpt4_' + reflection_mode_name + '_' + test_split[0]\n",
    "        print(exp_name)\n",
    "        dfs = [pd.read_csv('eppm_preds/random_for_train_10_' + str(i) + '_10.txt', sep=';;;', header=None) for i in range(3)]\n",
    "        contextualisation = get_self_reflection_samples(_df, dfs, choose=reflection_mode[0], options=reflection_mode[1])\n",
    "\n",
    "        preds, score = run_experiment(exp_name, None, contextualisation, lrml_col='spaced_lrml', everyNth=1, reversed=False, cot=False, step_by_step=False, should_display=False, self_reflect=True, self_reflect_df_names=test_split[3], options=reflection_mode[1], gpt4=use_gpt4, doc_split=test_split[1], valid_df=test_split[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/sj47dvbx7p9dd_l626f7j3700000gn/T/ipykernel_22410/1653513560.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dfs = [pd.read_csv('eppm_preds/context_full_perclause_reverse_71.txt', sep=';;;', header=None)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: CAS2 1.4.6 For the purposes of risk group SI the term 'bed' means the number of people that are under care or detention. It can include people on: a) Beds, or b) Recliner or lounge chairs, or c) Dentist chairs, or d) Treatment tables, or e) Any other furniture where an occupant may be for a period of treatment, in care or detention.\n",
      "(51.877711957171314, 'if( is( space. risk group, si)), then( define( bed, and( or( is( furniture, bed), is( furniture, recliner chair), is( furniture, lounge chair), is( furniture, dentist chair), is( furniture, treatment table), is( furniture, other)), is( furniture, occupant))))')\n",
      "Target: if( is( space. risk group, si)), then( and( is( bed, person), within( person, or( care, detention)), include( bed, or( recliner, lounge chair, dentist chair, treatment table, treatment furniture))))\n",
      "\n",
      "Source: CAS2 This Acceptable Solution is one of three Acceptable Solutions that provide a means of establishing compliance with NZBC Clauses C1 to C6 Protection from Fire. It can be used for the building activities covered by risk groups specified in Paragraph 1.1.1 and described in Table 1.1.\n",
      "(28.864273240933812, 'if( and( apply to( nzbc c1c6, building), as per( building. risk group, nzbc cas2 t1.1))), then( apply to( nzbc cas2, building))')\n",
      "Target: if( and( comply with( building, nzbc cas2), as per( building. risk group, and( nzbc cas2 1.1.1, nzbc cas2 t1.1)))), then( comply with( building. fire protection, and( nzbc c1, nzbc c2, nzbc c3, nzbc c5, nzbc c6)))\n",
      "\n",
      "Source: CAS2 2.3.11 Structural framing members connected to building elements with an FRR shall be rated at no less than the building elements to which they are connected. \n",
      "(49.441087149787904, 'if( and( has( structural framing member, connection), has( connection, fire resistance rating)), then( obligation( greater than equal( structural framing member. rating, connection. rating))))')\n",
      "Target: if( and( has( building, structural framing member), has( building, element), connect( building. structural framing member, element), has( element, fire resistance rating))), then( obligation( greater than equal( structural framing member. fire resistance rating, fire resistance rating)))\n",
      "\n",
      "Source: CAS2 3.1.1 All buildings shall have means of escape from fire which include escape routes. An escape route (see Figure 3.1) shall provide protection to any occupant escaping to a safe place from a fire within a building.\n",
      "(50.332833412942335, 'if( is( building, fire prone)), then( obligation( and( has( building, means of escape), has( means of escape, escape route), towards( escape route, safe place), from( fire, building), provide( escape route, protection), for( protection, occupants))))')\n",
      "Target: if( exist( building)), then( obligation( and( has( building, means of escape from fire), include( means of escape from fire, escape route), has( escape route, fire protection))))\n",
      "\n",
      "Source: CAS2 3.1.4 Escape routes shall comply with NZBC D1.\n",
      "(67.70485724879495, 'if( is( route, escape)), then( obligation( comply with( route, nzbc d1)))')\n",
      "Target: if( exist( escape route)), then( obligation( comply with( escape route, nzbc d1)))\n",
      "\n",
      "Source: CAS2 Ramps, stairs, ladders, landings, handrails, doors, vision panels and openings shall comply with Acceptable Solution D1/AS1.\n",
      "(77.03372131749504, 'if( or( is( element, ramp), is( element, stair), is( element, ladder), is( element, landing), is( element, handrail), is( element, door), is( element, vision panel), is( element, opening))), then( obligation( comply with( element, nzbc d1as1))))')\n",
      "Target: if( is( building. element, or( ramp, stair, ladder, landing, handrail, door, vision panel, opening))), then( obligation( comply with( building. element, nzbc d1as1)))\n",
      "\n",
      "Source: CAS2 4.1.1 Adjoining firecells are required to be fire separated from each other by the highest: a) Life rating specified in Paragraph 2.3 if both firecells are under common ownership, or b) Property rating specified in Paragraph 2.3 if both firecells are under different ownership.\n",
      "(58.07196192304922, 'if( adjoin( firecells)), then( obligation( and( in between( fire separation, firecells), if( equal( firecells. ownership, common)), then( define( max( firecells. life rating), x0)), if( equal( firecells. ownership, different)), then( define( max( firecells. property rating), x0))))))')\n",
      "Target: if( adjoin( firecells)), then( obligation( and( in between( fire separation, firecells), max( firecells. rating), or( and( define( max( firecells. life rating), x0), as per( firecells. life rating, nzbc cas2 2.3.0), is( fire separation. fire resistance rating, x0), equal( firecells. owner)), and( define( max( firecells. property rating), x0), as per( property rating, nzbc cas2 2.3.0), is( fire separation. fire resistance rating, x0), not( equal( firecells. owner)))))))\n",
      "\n",
      "Source: G12AS1 6.3.2 Open vented storage water heaters shall have a vent pipe complying with Paragraph 6.8.\n",
      "(79.09142641188147, 'if( is( storage water heater. type, open vented)), then( obligation( comply with( storage water heater. vent pipe, nzbc g12as1 6.8)))')\n",
      "Target: if( is( storage water heater. type, open vented)), then( obligation( and( has( storage water heater, ventilation pipe), comply with( ventilation pipe, nzbc g12as1 6.8))))\n",
      "\n",
      "Source: G12AS1 3.6.2 Manufacture; Backflow prevention devices shall be manufactured as follows: a) Reduced pressure zone devices to AS/NZS 2845.1 Section 12 (see Figure 2 (a)).\n",
      "(93.23164918970448, 'if( is( backflow prevention device, reduced pressure zone device)), then( obligation( comply with( backflow prevention device, nzs 2845 1 12)))')\n",
      "Target: if( is( backflow prevention device, reduced pressure zone device)), then( obligation( comply with( backflow prevention device. manufacturing, nzs 2845 1 12)))\n",
      "\n",
      "Source: G12AS1 6.9.1 NZS 4603 is an acceptable solution for open vented low pressure storage water heaters, but may exceed the performance criteria of NZBC G12.\n",
      "(74.28512564875429, 'if( is( storage water heater. type, open vented), then( permission( comply with( storage water heater, and( nzs 4603, not( comply with( storage water heater, nzbc g12))))))')\n",
      "Target: if( is( storage water heater. type, and( open vented, low pressure))), then( permission( comply with( storage water heater, nzs 4603)))\n",
      "\n",
      "Source: G12AS1 6.10.1 NZS 4607 is an acceptable solution for unvented (valve vented) storage water heaters, but may exceed the performance criteria of NZBC G12.\n",
      "(70.61433117947728, 'if( is( water heater. type, unvented)), then( permission( comply with( water heater, nzs 4607)))')\n",
      "Target: if( is( storage water heater. type, or( unvented, valve vented))), then( permission( comply with( storage water heater, nzs 4607)))\n",
      "\n",
      "Source: E1AS1 3.7.4 Inspection chambers or access chambers (see Figures 11 and 12) shall be provided where changes in both gradient and direction occur and where either is greater than 22.5°.\n",
      "(48.28574909059927, 'if( or( greater than( drain. gradient change, 22.5 deg), greater than( drain. direction change, 22.5 deg))), then( obligation( has( drain, or( inspection chamber, access chamber))))')\n",
      "Target: if( and( include( drain, and( change in direction, change in gradient)), define( change in gradient. location, x0), equal( change in direction. location, x0), or( greater than( change in direction, 22.5 deg), greater than( change in gradient, 22.5 deg)))), then( obligation( and( has( drain, access point), is( access point. type, or( inspection chamber, access chamber)), is( access point. location, x0))))\n",
      "\n",
      "Source: G12AS1 Pipes penetrating concrete or masonry elements shall be either wrapped with a flexible material, or passed through a sleeve or duct, to permit free movement for expansion and contraction.\n",
      "(62.095862501683705, 'if( and( is( penetration. material, or( concrete, masonry)), has( penetration, pipe)), then( obligation( or( and( has( pipe, wrapping), is( wrapping. material, flexible)), and( has( pipe, sleeve), or( is( sleeve. type, sleeve), is( sleeve. type, duct))))))')\n",
      "Target: if( and( into( pipe, element), is( element. material, or( concrete, masonry)))), then( obligation( or( and( has( pipe, wrapping), is( wrapping. material, flexible)), through( pipe, and( sleeve, duct)))))\n",
      "\n",
      "Source: E1AS1 2.0.1 Suspended floors and slabs on ground shall be at least 150 mm above the finished level of the surrounding ground immediately adjacent to the building.\n",
      "(91.42069437475786, \"if( or( is( floor. type, suspended), on( slab, ground))), then( obligation( and( adjacent( building, ground), define( ground. level, x0), greater than equal( floor. elevation, 'x0 + 150 mm'), greater than equal( slab. elevation, 'x0 + 150 mm'))))\")\n",
      "Target: if( or( is( floor. type, suspended), on( slab, ground))), then( obligation( and( adjacent( ground, building), define( ground. elevation, x0), greater than equal( floor. elevation, 'x0 + 150 mm'), greater than equal( slab. elevation, 'x0 + 150 mm'))))\n",
      "\n",
      "Source: E1AS1 Drains shall be capable of handling the rainfall during a storm. No drain shall have an internal diameter of less than 85 mm.\n",
      "(68.82532669054235, 'if( is( drain, any)), then( obligation( and( greater than equal( drain. diameter, 85 mm), as per( drain. capacity, rainfall during a storm))))')\n",
      "Target: if( exist( drain)), then( obligation( and( for( drain, storm water), greater than equal( drain. internal diameter, 85 mm))))\n",
      "\n",
      "Source: G12AS1 6.7.1 Relief valve drains (see Figures 12 and 13) shall be fitted to: a) Temperature/pressure relief valves, Pressure relief valves, and c) Expansion control valves.\n",
      "(72.17645721430365, 'if( or( is( valve. type, temperature/pressure relief), is( valve. type, pressure relief), is( valve. type, expansion control))), then( obligation( has( valve, relief valve drain), as per( relief valve drain, and( nzbc g12as1 f12, nzbc g12as1 f13)))))')\n",
      "Target: if( is( valve. type, or( temperature pressure relief, pressure relief, expansion control))), then( obligation( has( valve, relief valve drain)))\n",
      "\n",
      "Source: E1AS1 Acceptable fill materials shown in Figure 13 are: Selected compacted fill of any fine-grained soil or granular material which is free from topsoil and rubbish and has a maximum particle size of 20 mm.\n",
      "(71.11510987556716, 'if( is( fill material, selected compacted fill)), then( obligation( and( is( selected compacted fill, and( fine grained soil, granular material)), not( include( selected compacted fill, or( topsoil, rubbish))), less than equal( selected compacted fill. particle size, 20 mm))))')\n",
      "Target: if( and( is( fill material, bedding material), is( fill material. type, compacted))), then( obligation( and( is( fill material, or( fine grained soil, granular)), not( include( fill material, and( topsoil, rubbish))), less than equal( fill material. particle size, 20 mm))))\n",
      "\n",
      "Source: B1AS1 The earthquake zone factor > 0.6 shall apply to the Canterbury earthquake region.\n",
      "(35.89012956419317, 'if( is( region, canterbury earthquake)), then( is( earthquake zone factor, greater than( 0.6)))')\n",
      "Target: if( exist( canterbury earth quake region)), then( obligation( greater than( canterbury earth quake region. earth quake zone factor, 0.6)))\n",
      "\n",
      "Source: B1AS1 Structure Design; Interlinking rails are not required for a heat-strengthened or toughened laminated safety glass barrier that: has two or three edges supported by structural sealant joints or continuous clamps, and will, when both panes of the laminate are fractured, resist a 0.2 kN concentrated load and not deflect more than 250 mm (see note 2).\n",
      "(80.21617390874518, 'if( and( is( safety barrier. material, glass), is( glass. type, laminated), is( glass, or( heat strengthened, toughened)), has( glass, or( structural sealant joint, continuous clamp), for( edge, supported), is( edge. type, or( two edges, three edges))), is( safety barrier. panes, and( laminate, fractured)), against( panes. resistance, concentrated load), less than equal( concentrated load, 0.2 kN), is( resistance. type, concentrated load), less than equal( panes. deflection, 250 mm))), then( permission( not( is( safety barrier. rail, interlinked))))')\n",
      "Target: if( and( is( safety barrier. material, glass), is( glass. type, laminated), is( glass, or( heat strengthened, toughened)), equal( count( safety barrier. edge), or( 2, 3)), is( edge. support, or( sealant joint, continuous clamp)), is( safety barrier. panes, and( laminate, fractured)), against( panes. resistance, concentrated load), less than equal( concentrated load, 0.2 kN), is( resistance. type, concentrated load), less than equal( panes. deflection, 250 mm))), then( permission( not( is( safety barrier. rail, interlinked))))\n",
      "\n",
      "Source: E2AS1 4.3.10 Bituminous flashings; Bituminous flashings shall only be used in accordance with Table 20.\n",
      "(93.33333333333333, 'if( is( flashing. material, bituminous)), then( obligation( as per( flashing, nzbc e2as1 t20)))')\n",
      "Target: if( is( flashing. material, bituminous)), then( obligation( as per( flashing. application, nzbc e2as1 t20)))\n",
      "\n",
      "Source: E2AS1 Cladding systems shall meet the requirements of NZBC E2.2 to E2.3.7.\n",
      "(64.12125227762134, 'if( include( building. envelope, cladding system)), then( obligation( comply with( cladding system, nzbc e2 2 to nzbc e2 3.7)))')\n",
      "Target: if( exist( cladding system)), then( obligation( comply with( cladding system, nzbc e2 2 to nzbc e2 3.7)))\n",
      "\n",
      "Source: B1AS1 NZS 4223.3 Glass design for these types shall comply with the following tables (see note 1): Table 16 - Structural balustrade – two-edge support;.\n",
      "(100.0, 'if( and( is( structure, balustrade), is( balustrade. design, two edge support))), then( obligation( comply with( balustrade. design, nzs 4223 3 t16)))')\n",
      "Target: if( and( is( structure, balustrade), is( balustrade. design, two edge support))), then( obligation( comply with( balustrade. design, nzs 4223 3 t16)))\n",
      "\n",
      "Source: E2AS1 7.1.1 Slatted decks; The level of the upper surface of the slatted deck: May be at the same level as the threshold for non-cantilevered decks that are formed as shown in Figure 14(c).\n",
      "(69.00382599990944, 'if( is( deck. type, slatted)), then( permission( and( define( deck. level, x0), equal( deck. level, threshold. elevation), is( threshold. type, non-cantilevered deck), as per( threshold, nzbc e2as1 f14.c))))')\n",
      "Target: if( and( is( deck, slatted), not( is( deck, cantilevered)), as per( deck, nzbc e2as1 f14.c))), then( permission( and( define( deck. threshold level, x0), equal( deck. upper surface level, x1))))\n",
      "\n",
      "Source: E2AS1 8.2.1.1 Tile profiles; Type II: Single profile tiles having one water- course depth of a minimum of 25 mm.\n",
      "(78.89779875144714, 'if( is( tile. type, single profile)), then( greater than equal( tile. watercourse. depth, 25 mm))')\n",
      "Target: if( is( tile. type, single profile)), then( and( equal( count( tile. watercourse), 1), greater than equal( watercourse. depth, 25 mm)))\n",
      "\n",
      "Source: E2AS1 Roof cladding; Where required in AS 2050 and Table 20, underlay shall comply with Table 23.\n",
      "(65.68645373696103, 'if( has( roof cladding, underlay), and( apply to( underlay, as 2050)), then( obligation( comply with( underlay, nzbc e2as1 t23))))')\n",
      "Target: if( and( requires( roof cladding, underlay), as per( underlay, and( as 2050, nzbc e2as1 t20)))), then( obligation( comply with( underlay, nzbc e2as1 t23)))\n",
      "\n",
      "Source: E2AS1 Handrails; Fixing of posts for handrails into membrane roofs or decks is not covered by this Acceptable Solution.\n",
      "(56.77017478633887, 'if( and( is( handrail, post), towards( post. fixing, or( membrane roof, deck)))), then( not( apply to( nzbc e2as1, post. fixing)))')\n",
      "Target: if( and( for( membrane, or( roof, deck)), into( post. fixing, membrane), for( post, handrail))), then( not( apply to( nzbc e2as1, fixing)))\n",
      "\n",
      "Source: E2AS1 8.4.13 Stopends; The top ends of profiled metal roof cladding shall have stopends as shown in Figure 49 for trapezoidal and trough profile metal roof cladding, where: a) The roof pitch is less than 25°, or b) The building is in a High/Very High/Extra High wind zone.\n",
      "(83.61149666278187, 'if( is( roof cladding. type, profiled metal), then( obligation( and( has( roof cladding. top end, stopend), as per( stopend, nzbc e2as1 f49), or( less than( roof. pitch, 25 deg), is( building. wind zone, or( high, very high, extra high))))))')\n",
      "Target: if( and( is( roof cladding. type, profiled metal), is( roof cladding. profile, or( trapezoidal, trough)), or( less than( roof. pitch, 25 deg), is( building. wind zone, or( high, very high, extra high))))), then( obligation( and( has( cladding. top end, stopend), as per( stopend, nzbc e2as1 f49))))\n",
      "\n",
      "Source: E2AS1 9.1.3.5 Bottom of wall claddings for timber floor framing; Suspended timber floors shall meet the requirements of NZS 3604. Clearances from paved and unpaved surfaces to the wall framing shall be in accordance with NZS 3604, and Table 18.\n",
      "(49.535483879790704, 'if( and( is( floor. type, suspended timber), comply with( floor, nzs 3604))), then( obligation( and( has( wall cladding. bottom, clearance), towards( clearance, surface), comply with( clearance, and( nzbc e2as1 t18, nzs 3604)))))')\n",
      "Target: if( and( adjacent( floor, wall cladding), is( floor, suspended), is( floor. material, timber))), then( obligation( and( comply with( floor, nzs 3604), towards( wall cladding. clearance, surface), is( surface, or( paved, unpaved)), as per( wall cladding. clearance, and( nzs 3604, nzbc e2as1 t18)))))\n",
      "\n",
      "Source: G12AS2 4.2.1 Solar collectors must face within +/- 90 degrees of geographic north (ie between east and west) to satisfy the requirements of NZBC Clause H1.3.4(a).\n",
      "(78.1017870931749, \"if( exist( solar collector)), then( obligation( within( solar collector. facing, '+/- 90 degreesOfGeographicNorth')))\")\n",
      "Target: if( exist( solar collector)), then( obligation( within( solar collector. orientation, ' +/- 90 degreesOfGeographicalNorth')))\n",
      "\n",
      "Source: G12AS2 5.0.3 Fixings used for the installation of a solar water heater must meet the requirements described in Paragraphs 2.1.1, 2.1.2, 2.1.3 and 2.1.4.\n",
      "(97.05760199354654, 'if( has( solar water heater. installation, fixing)), then( obligation( and( comply with( fixing, and( nzbc g12as2 2.1.1, nzbc g12as2 2.1.2, nzbc g12as2 2.1.3, nzbc g12as2 2.1.4)))))')\n",
      "Target: if( has( solar water heater. installation, fixing)), then( obligation( comply with( fixing, and( nzbc g12as2 2.1.1, nzbc g12as2 2.1.2, nzbc g12as2 2.1.3, nzbc g12as2 2.1.4))))\n",
      "\n",
      "Source: E2AS1 Parapets shall comply with Paragraph 6.0.\n",
      "(100.0, 'if( exist( parapet)), then( obligation( comply with( parapet, nzbc e2as1 6.0)))')\n",
      "Target: if( exist( parapet)), then( obligation( comply with( parapet, nzbc e2as1 6.0)))\n",
      "\n",
      "Source: G12AS2 3.1.2 Tanks installed as part of a pumped solar water heater where the tank is separately mounted from the collector must comply with the minimum tank insulation requirements of AS/NZS 4692.2.\n",
      "(51.66218471351404, 'if( and( is( water heater. type, pumped solar), has( water heater, tank), not( connect( water heater. tank, water heater. collector))), then( obligation( comply with( water heater. tank insulation, as/nzs 4692.2))))')\n",
      "Target: if( and( part of( tank, solar water heater), is( solar water heater. type, pumped), away from( tank, collector))), then( obligation( comply with( tank. insulation, nzs 4692 2)))\n",
      "\n",
      "Source: G12AS2 Roof Framing 6.2.7 The centre of all fixings must be no closer than 10 fixing diameters from the end of a piece of timber.\n",
      "(66.13611227120542, \"if( has( roof framing, fixing)), then( obligation( and( define( fixing. centre, x0), define( timber. length, x1), define( fixing. diameter, x2), less than equal( x0, 'x1 - 10 * x2'))))\")\n",
      "Target: if( has( timber section, fixing)), then( obligation( and( define( fixing. centre, x0), define( timber section. end, x1), in between( distance, and( x0, x1)), define( fixing. diameter, x2), greater than equal( distance, '10 * x2'))))\n",
      "\n",
      "Source: G12AS2 6.4.2 Solar collectors mounted parallel to the roof that are elevated up to 50 mm above the roof cladding must be supported by: a) underlying purlins conforming to Paragraph 6.4.1 (a) or (b), or b) underlying rafters or trusses with connections conforming with Paragraphs 6.4.1 (a) or (c), or c) collector support rails conforming to Paragraph 6.5.\n",
      "(58.697898331474185, \"if( and( is( solar collector. orientation, parallel), above( solar collector. elevation, roof cladding), less than equal( solar collector. elevation, 'roof cladding + 50 mm'))), then( obligation( or( and( has( solar collector, support), is( support. type, purlin), comply with( purlin, or( nzbc g12as2 6.4.1a, nzbc g12as2 6.4.1b))), and( has( solar collector, support), is( support. type, rafter or truss), comply with( support, or( nzbc g12as2 6.4.1a, nzbc g12as2 6.4.1c))), and( has( solar collector, support), is( support. type, collector support rail), comply with( collector support rail, nzbc g12as2 6.5)))))\")\n",
      "Target: if( and( is( solar collector. orientation, parallel), towards( solar collector. orientation, roof), above( solar collector. elevation, roof cladding), less than equal( solar collector. elevation, 50 mm))), then( obligation( or( and( is( solar collector. support, purlin), below( purlin, solar collector), comply with( purlin, or( nzbc g12as2 6.4.1.a, nzbc g12as2 6.4.1.b))), and( is( solar collector. support, rafter), below( rafter, solar collector), comply with( rafter. connection, or( nzbc g12as2 6.4.1.a, nzbc g12as2 6.4.1.c))), and( is( solar collector. support, truss), below( truss, solar collector), comply with( truss. connection, or( nzbc g12as2 6.4.1.a, nzbc g12as2 6.4.1.c))), and( is( solar collector. support, support rail), comply with( support rail, nzbc g12as2 6.5)))))\n",
      "\n",
      "Source: G13AS1 5.1.1 Discharge pipes shall be vented where required by Table 5.\n",
      "(70.66666666666667, 'if( exist( discharge pipe)), then( obligation( comply with( discharge pipe. venting, nzbc g13as1 t5)))')\n",
      "Target: if( exist( discharge pipe)), then( obligation( as per( discharge pipe. ventilation, nzbc g13as1 t5)))\n",
      "\n",
      "Source: G13AS1 5.8.2 Air admittance valves shall be manufactured to ASSE 1050, ASSE 1051, EN 12380 or AS/NZS 4936.\n",
      "(85.10886418149774, 'if( is( air admittance valve, exist)), then( obligation( comply with( air admittance valve, or( asse 1050, asse 1051, en 12380, nzs 4936))))')\n",
      "Target: if( exist( air admittance valve)), then( obligation( comply with( air admittance valve. manufacturing, or( asse 1050, asse 1051, en 12380, nzs 4936))))\n",
      "\n",
      "Source: G13AS1 3.1.2 Water traps shall be: a) Removable, b) Able to be dismantled, or c) Fitted with a cleaning eye.\n",
      "(84.9401450504278, 'if( exist( water trap)), then( obligation( or( is( water trap. type, removable), is( water trap. type, dismantlable), has( water trap, cleaning eye))))')\n",
      "Target: if( exist( water trap)), then( obligation( or( is( water trap, or( removable, dismantleable)), has( water trap, cleaning eye))))\n",
      "\n",
      "Source: G13AS1 Individual floor waste pipes connected to a floor waste stack need not be vented (see Figure 3).\n",
      "(37.107752416203994, 'if( and( has( floor waste, pipes), is( connect( pipes), floor waste stack))), then( permission( not( has( pipes, ventilation))))')\n",
      "Target: if( within( pipe, floor waste stack)), then( permission( not( has( pipe, ventilation))))\n",
      "\n",
      "Source: G13AS2 5.1.1 Rigid pipes shall have flexible joints to resist damage from differential settlement.\n",
      "(73.7466307277628, 'if( is( pipe. type, rigid)), then( obligation( has( pipe, joint), is( joint. flexibility, flexible), towards( joint. resistance, differential settlement)))')\n",
      "Target: if( is( pipe, rigid)), then( obligation( and( has( pipe, joint), is( joint, flexible))))\n",
      "\n",
      "Source: G13AS2 5.9.3 Access points may be located in a space containing a soil fixture.\n",
      "(89.117199391172, 'if( exist( access point)), then( permission( within( access point. location, space), has( space, soil fixture)))')\n",
      "Target: if( exist( access point)), then( permission( and( within( access point. location, space), include( space, soil fixture))))\n",
      "\n",
      "Source: G13AS2 5.10.1 Where a drain or part of a drain is no longer required, it shall be disconnected from the foul water drainage system at the junction with the live drain or at the property boundary.\n",
      "(41.46487627606222, 'if( exist( drain)), then( obligation( or( is( drain, disconnected), towards( drain. disconnection, or( live drain, property boundary)))))')\n",
      "Target: if( or( not( is( drain, required)), not( is( drain. part, required)))), then( obligation( or( disconnect( drain, or( live drain junction, property boundary)), disconnect( drain. part, or( live drain junction, property boundary)))))\n",
      "\n",
      "Source: G13AS2 3.5.1 Drains shall: a) Be laid at an even grade, and b) Have no obstructions to flow.\n",
      "(76.2507689153168, 'if( exist( drain)), then( obligation( and( is( drain. grade, even), not( exist( obstruction, towards( obstruction, flow))))))')\n",
      "Target: if( exist( drain)), then( obligation( and( is( drain. grade, even), not( has( drain. flow, obstruction)))))\n",
      "\n",
      "Source: G15AS1 4.0.1 Where waste chutes with side-entry hoppers (see Figure 2) are used as an alternative to common storage areas, the chute shall: a) Have a minimum internal diameter of 450 mm, b) Be self-cleaning, vertical and have smooth joints, c) Be vented at the top above the roof line, and at the bottom above the container, and d) Terminate centrally over a suitable container located in a room complying with Paragraphs 3.0.1 to 3.0.9.\n",
      "(60.25295824890355, 'if( is( waste chute. type, side-entry), then( obligation( and( greater than equal( waste chute. diameter, 450 mm), is( waste chute. cleaning, self), is( waste chute. orientation, vertical), has( waste chute, smooth joints), has( waste chute, ventilation), towards( ventilation. location, and( top, roof line)), towards( ventilation. location, and( bottom, container)), has( waste chute, termination), towards( termination. location, and( central, container)), is( container. location, room), comply with( room, and( nzbc g15as1 3.0.1, nzbc g15as1 3.0.9))))))')\n",
      "Target: if( and( has( waste chute, site entry hopper), not( exist( waste storage area)), is( waste storage area. type, common))), then( obligation( and( greater than equal( waste chute. internal diameter, 450 mm), is( waste chute, self cleaning), is( waste chute, vertical), is( waste chute. joint, smooth), has( waste chute. top, ventilation), above( ventilation, roof line), has( waste chute. bottom, ventilation), above( ventilation, container), is( waste chute. termination point, central), above( waste chute. termination point, container), is( container. location, space), comply with( space, nzbc g15as1 3.0.1 to nzbc g15as1 3.0.9))))\n",
      "\n",
      "Source: B1AS3 1.1.1 Type; The acceptable solutions described in this document are for chimneys built of brickwork, concrete or precast pumice concrete, that are connected to timber frame or masonry buildings complying with NZS 3604 or NZS 4229.\n",
      "(81.87019472865887, 'if( is( chimney. material, or( brickwork, concrete, precast pumice concrete)), and( is( building, or( timber frame, masonry)), comply with( building, or( nzs 3604, nzs 4229))), then( obligation( is( chimney. type, acceptable solution)))')\n",
      "Target: if( and( is( chimney. material, or( brickwork, concrete, precast pumice concrete)), connect( chimney, building), is( building. material, or( timber frame, masonry)), comply with( building, or( nzs 3604, nzs 4229)))), then( apply to( nzbc b1as3, chimney))\n",
      "\n",
      "Source: G15AS1 3.0.3 Walls in spaces where storage bins are likely to receive food wastes and are subject to spillage shall be constructed of concrete, galvanised sheet steel, vinyl or similar material.\n",
      "(62.34177774903479, 'if( and( is( wall. space, storage bin), include( wall. risk group, food waste), include( wall. task, spillage)), then( obligation( is( wall. material, or( concrete, galvanised sheet steel, vinyl, similar material))))')\n",
      "Target: if( and( has( space, and( wall, storage bin)), into( food waste, storage bin), has( storage bin, spillage))), then( obligation( or( is( wall. material, or( concrete, galvanised steel sheet, vinyl)), similar to( wall. material, or( concrete, galvanised steel sheet, vinyl)))))\n",
      "\n",
      "Source: G15AS1 Waste Storage Area 3.0.6 opening windows shall be screened to prevent entry by insects and other vermin.\n",
      "(67.09051134809954, 'if( has( waste storage area, opening window)), then( obligation( screened from( opening window, and( insect, vermin))))')\n",
      "Target: if( and( has( waste storage area, window), is( window, openable))), then( obligation( screened from( window, vermin)))\n",
      "\n",
      "Source: G15AS1 3.0.7 A water supply tap, complying with NZBC G12, shall be provided for washing down common waste storage areas.\n",
      "(98.73417721518987, 'if( is( waste storage area. type, common)), then( obligation( has( waste storage area, water supply tap), comply with( water supply tap, nzbc g12)))')\n",
      "Target: if( is( waste storage area. type, common)), then( obligation( and( has( waste storage area, water supply tap), comply with( water supply tap, nzbc g12))))\n",
      "\n",
      "Source: B1AS3 1.9.1 The bracing described in Paragraphs 1.9.2 to 1.9.6 shall be provided in those buildings where one or more of the following apply: a) The area of the room containing the chimney exceeds 24 m2, c) The floor area on any level of the building, for a given chimney type (see Table 2), is less than: i) 50 m2 for chimney Type 1, ii) 75 m2 for chimney Types 2, 3 and 4, iii) 150 m2 for chimney Types 5, 6 and 7.\n",
      "(39.87143098826324, 'if( and( is( building, or( room, floor)), has( building, chimney), or( greater than( room. area, 24 m2), less than( floor. area, and( or( is( chimney. type, 1), is( chimney. type, 2), is( chimney. type, 3), is( chimney. type, 4)), or( and( is( chimney. type, 5), less than( floor. area, 150 m2)), and( is( chimney. type, 6), less than( floor. area, 150 m2)), and( is( chimney. type, 7), less than( floor. area, 150 m2))))))), then( obligation( for each( building, bracing), comply with( bracing, nzbc b1as3 1.9.2 to 1.9.6))))')\n",
      "Target: if( or( and( include( building. space, chimney), greater than( space. area, 24 m2)), and( less than( building storey. floor area, 50 m2), is( chimney. type, type 1)), and( less than( building storey. floor area, 75 m2), is( chimney. type, or( type 2, type 3, type 4))), and( less than( building storey. floor area, 150 m2), is( chimney. type, or( type 5, type 6, type 7))))), then( obligation( and( has( building, bracing), as per( bracing, nzbc b1as3 1.9.2 to nzbc b1as3 1.9.6))))\n",
      "\n",
      "Source: B1AS3 1.9.3 The number of bracing units to be provided for each chimney connection (see Paragraph 1.9.4) is given in Table 2.\n",
      "(47.451540860918904, 'if( has( building, chimney)), then( obligation( and( define( chimney. connection, x0), as per( count( bracing unit), and( x0, nzbc b1as3 t2)), as per( bracing unit, nzbc b1as3 1.9.4))))')\n",
      "Target: if( exist( chimney)), then( obligation( loop( for each( chimney. connection), as per( count( bracing. unit), nzbc b1as3 t2))))\n",
      "\n",
      "Source: B1AS3 1.9.4 A chimney shall be considered as connected to the building when: a) At roof level: it is held either by a roof bracket or by a roof tie.\n",
      "(73.15922519179398, 'if( is( chimney. elevation, roof level), or( is( chimney. fixing, roof bracket), is( chimney. fixing, roof tie))), then( connect( chimney, building))')\n",
      "Target: if( and( has( chimney, fixing), is( fixing. type, or( roof bracket, roof tie)), is( fixing. elevation, roof level))), then( connect( chimney, building))\n",
      "\n",
      "Source: B1AS3 Fixing Ties; The ties shall be located at no less than 320 mm centres for stacks up to 600 mm wide.\n",
      "(89.06272223012375, 'if( and( is( tie. type, fixing), less than equal( stack. width, 600 mm))), then( obligation( greater than equal( tie. location, 320 mmCentres)))')\n",
      "Target: if( and( is( tie. type, fixing), for( tie, stack), less than equal( stack. width, 600 mm))), then( obligation( greater than equal( tie. location, 320 mmCentres)))\n",
      "\n",
      "Source: G14VM1 1.4.1 Disposal systems shall be located: To ensure that spillage from storage tanks or ponds can be safely contained.\n",
      "(100.0, 'if( exist( disposal system)), then( obligation( has( disposal system. location, spillage containment)))')\n",
      "Target: if( exist( disposal system)), then( obligation( has( disposal system. location, spillage containment)))\n",
      "\n",
      "Source: G14VM1 1.4.1 Collection facilities shall be located: In areas with sufficient access for cleaning, clearing of blockages, and maintenance.\n",
      "(100.0, 'if( exist( collection facility)), then( obligation( and( has( collection facility. location, access), for( access, or( cleaning, blockage clearing, maintenance)))))')\n",
      "Target: if( exist( collection facility)), then( obligation( and( has( collection facility. location, access), for( access, or( cleaning, blockage clearing, maintenance)))))\n",
      "\n",
      "Source: B1AS1 Structure Design 8.0 Small Chimneys; See Acceptable Solution B1/AS3.\n",
      "(73.89075481704084, 'if( and( is( structure, chimney), is( chimney. size, small))), then( apply to( nzbc b1as3, structure))')\n",
      "Target: if( and( is( structure, chimney), is( chimney. size, small))), then( as per( chimney. design, nzbc b1as3))\n",
      "\n",
      "Source: G14VM1 2.0.1 Where the network utility operator accepts the discharge of industrial liquid waste to a sewer, the waste shall be conveyed in a plumbing and drainage disposal system complying with NZBC G13 Foul Water.\n",
      "(74.89387783049511, 'if( and( for( disposal system, industrial liquid waste), is( disposal system. disposal method, discharge), accept( network utility operator, discharge), into( discharge, sewer))), then( obligation( comply with( disposal system, nzbc g13 foul water)))')\n",
      "Target: if( and( accept( network utility operator, discharge), is( discharge. type, industrial liquid waste), into( discharge, sewer))), then( obligation( and( within( industrial liquid waste, disposal system), for( disposal system, and( plumbing, drainage)), comply with( disposal system, nzbc g13))))\n",
      "\n",
      "Source: G14VM1 2.1.1 Screens, grit chambers, grease traps or similar appropriate equipment should be installed at the head of piping systems if suspended solids or material within the liquid waste might cause blockage of the piping system.\n",
      "(27.558773917219387, 'if( exist( piping system)), then( obligation( and( has( piping system, equipment), is( equipment. type, or( screen, grit chamber, grease trap)), towards( equipment, head), for( material, piping system), is( material. type, or( suspended solid, waste)), requires( equipment, prevent( material, blockage)))))')\n",
      "Target: if( and( cause( liquid waste, blockage), within( blockage, piping system))), then( obligation( or( has( piping system. head, or( screen, grit chamber, grease trap)), similar to( piping system. head, or( screen, grit chamber, grease trap)))))\n",
      "\n",
      "Source: G14VM1 2.1.2 Wherever possible, piping systems shall convey industrial liquid waste using gravity flow.\n",
      "(70.7996472144642, 'if( exist( piping system)), then( obligation( and( is( piping system. method, gravity flow), towards( piping system, industrial liquid waste))))')\n",
      "Target: if( and( for( piping system, industrial liquid waste), is( piping system. gravity flow, possible))), then( obligation( is( piping system. method, gravity flow)))\n",
      "\n",
      "Source: E2AS1 Galvanized steel flashings shall: a) have a BMT of 0.55 mm minimum b) be grade G550, or G300 for rolled or crimped flashings c) be selected for corrosion protection according to the intended exposure zone as shown in Table 20.\n",
      "(91.75678006624736, 'if( is( flashing. material, galvanized steel)), then( obligation( and( greater than equal( flashing. base metal thickness, 0.55 mm), or( equal( flashing. grade, g550), and( equal( flashing. grade, g300), is( flashing. type, or( rolled, crimped)))), as per( flashing. corrosion protection, intended exposure zone), as per( intended exposure zone, nzbc e2as1 t20))))')\n",
      "Target: if( and( is( flashing. material, steel), is( steel. type, galvanised))), then( obligation( and( greater than equal( flashing. base metal thickness, 0.55 mm), or( equal( flashing. grade, g550), and( equal( flashing. grade, g300), is( flashing. type, or( rolled, crimped)))), as per( flashing. corrosion protection, intended exposure zone), as per( intended exposure zone, nzbc e2as1 t20))))\n",
      "\n",
      "Source: E2AS1 Buildings with drained cavities and acoustic requirements, as specified in NZBC Clause G6, are outside the scope of this Acceptable Solution.\n",
      "(92.73574606518436, 'if( and( has( building, and( drained cavity, acoustic requirement)), is( acoustic requirement, nzbc g6))), then( not( apply to( nzbc e2as1, building)))')\n",
      "Target: if( and( has( building, and( drained cavity, acoustic requirement)), as per( acoustic requirement, nzbc g6))), then( not( apply to( nzbc e2as1, building)))\n",
      "\n",
      "Source: E2AS1 Joins of metal flashings shall have the following features: Lap joins on other metal flashings (i.e. not rules 4.5.2.0.2.e.1 and 4.5.2.0.2.f.1) shall be sealed using a neutral cure silicone sealant in conjunction with mechanical fasteners. The sealant shall comply with: a) Type F, Class 20LM or 25LM of ISO 11600, or b) low modulus Type II Class A of Federal Specification TT-S-00230C.\n",
      "(63.14019486857123, 'if( and( is( flashing. material, metal), has( flashing. join, lap), not( or( is( join, nzbc e2as1 4.5.2.0.2.e.1), is( join, nzbc e2as1 4.5.2.0.2.f.1)))), then( obligation( and( has( join, sealant), adjoin( sealant, mechanical fastener), is( sealant. type, neutral cure silicone), comply with( sealant, or( iso 11600 type f, iso 11600 class 20lm, iso 11600 class 25lm, tts 00230c low modulus type ii class a)))))')\n",
      "Target: if( and( is( flashing. material, metal), has( flashing. join, lap), not( apply to( nzbc e2as1 4.5.2.0.2.e.1, flashing)), not( apply to( nzbc e2as1 4.5.2.0.2.f.1, flashing)))), then( obligation( and( by( lap. seal, and( sealant, mechanical fastener)), is( sealant. type, neutral cure silicone), comply with( sealant, or( iso 11600 type f class 20lm, iso 11600 type f class 25lm, tts 00230c low modulus type ii class a)))))\n",
      "\n",
      "Source: E2AS1 4.6 Flashing overlaps and upstands; Overlaps and upstands to flashings shall be as specified in this paragraph and Table 7.\n",
      "(63.10776577596467, 'if( exist( flashing)), then( obligation( and( as per( flashing. overlap, and( nzbc e2as1 4.6, nzbc e2as1 t7)), as per( flashing. upstand, and( nzbc e2as1 4.6, nzbc e2as1 t7)))))')\n",
      "Target: if( has( flashing, or( lap, upstand))), then( obligation( and( as per( lap, and( nzbc e2as1 4.6, nzbc e2as1 t7)), as per( upstand, and( nzbc e2as1 4.6, nzbc e2as1 t7)))))\n",
      "\n",
      "Source: E2AS1 4.0 Flashings 4.6.1.6 Window and door heads; Overlap cover of cladding to the flashing upstand and clearance from the bottom of the cladding to top of head flashing slope shall be in accordance with Table 7.\n",
      "(97.45264532984977, 'if( for( flashing, or( window head, door head))), then( obligation( and( has( flashing, upstand), above( flashing, cladding), in between( overlap cover, and( cladding, upstand)), has( cladding, bottom), has( flashing. head, slope), has( slope, top), in between( clearance, and( bottom, top)), as per( overlap cover, nzbc e2as1 t7), as per( clearance, nzbc e2as1 t7))))')\n",
      "Target: if( for( flashing. type, or( window head, door head))), then( obligation( and( has( flashing, upstand), above( flashing, cladding), in between( overlap cover, and( cladding, upstand)), has( cladding, bottom), has( flashing. head, slope), has( slope, top), in between( clearance, and( bottom, top)), as per( overlap cover, nzbc e2as1 t7), as per( clearance, nzbc e2as1 t7))))\n",
      "\n",
      "Source: E2AS1 4.0 Flashings 4.6.1.3 Change in metal roof pitches; a) There shall be a minimum effective lap under roof cladding in accordance with Table 7, with a hem at upper edge.\n",
      "(46.760273741208806, 'if( is( flashing. type, change in pitch)), then( obligation( and( has( flashing, lap), greater than equal( lap. size, and( nzbc e2as1 t7, hem)), has( lap, hem), towards( hem, lap), above( hem, roof cladding))))')\n",
      "Target: if( and( has( metal roofing. pitch, change), for( flashing, change))), then( obligation( and( below( lap, cladding), is( lap, minimum effective), as per( lap, nzbc e2as1 t7), is( lap. edge, upper), has( lap. edge, hem))))\n",
      "\n",
      "Source: E2AS1 8.4 Profiled Metal Roof Cladding; Fixings shall: a) Be fixed through crests, b) Penetrate purlins by a minimum of 40 mm for nail fixings and 30 mm for screw fixings, c) Include sealing washers of: i) neoprene (having a carbon black content of 15% or less by weight).\n",
      "(79.70295841252208, 'if( is( roof cladding. type, profiled metal), has( roof cladding, fixing), and( is( fixing. type, or( nail, screw)), greater than equal( fixing. penetration, or( 40 mm, 30 mm))), then( obligation( and( include( fixing, sealing washer), is( sealing washer. type, neoprene), has( neoprene, carbon black content), less than equal( neoprene. carbon black content, 15 percent), by( neoprene, weight))))')\n",
      "Target: if( and( is( roof cladding. type, profiled metal), has( roof cladding, fixing))), then( obligation( and( has( roof cladding, crest), through( fixing, crest), into( fixing. penetration, purlin), or( and( is( fixing. type, nail), greater than equal( fixing. penetration, 40 mm)), and( is( fixing. type, screw), greater than equal( fixing. penetration, 30 mm))), include( fixing, sealing washer), is( sealing washer. type, neoprene), less than equal( sealing washer. carbon black content, 15 percent))))\n",
      "\n",
      "Source: E2AS1 9.1.3.3 Bottom of wall claddings for concrete ground slabs (except masonry veneer); At concrete slab level, the base of the cladding system shall be as shown in Table 18, and: a) Finish a minimum of: i) 100 mm above a paved surface, or ii) 175 mm above finished unpaved surface, b) Overlap the concrete slab by 50 mm, and c) Be offset horizontally by a minimum of 6 mm for direct fixed claddings to prevent capillary action.\n",
      "(68.48219085879073, 'if( and( adjoin( wall cladding, concrete slab), not( is( wall cladding. type, masonry veneer))), then( obligation( and( as per( wall cladding. bottom, nzbc e2as1 t18), towards( wall cladding. finish, surface), or( and( greater than equal( wall cladding. finish, 100 mm), is( surface. type, paved)), and( greater than equal( wall cladding. finish, 175 mm), is( surface. type, unpaved))), has( wall cladding. bottom, lap), towards( lap, slab), equal( lap. size, 50 mm), is( wall cladding. type, direct fixed), has( wall cladding. bottom, offset), is( offset, horizontal), towards( offset, slab), greater than equal( offset. size, 6 mm))))')\n",
      "Target: if( and( not( is( wall cladding. system, masonry veneer)), adjoin( slab, wall cladding), is( slab. type, ground), is( slab. material, concrete))), then( obligation( and( comply with( wall cladding. bottom, nzbc e2as1 t18), or( and( adjoin( surface, wall cladding), is( surface. type, paved), define( surface. elevation, x0), greater than equal( wall cladding. bottom, 'x0 + 100 mm')), and( adjoin( surface, wall cladding), not( is( surface. type, paved)), define( surface. elevation, x0), greater than equal( wall cladding. bottom, 'x0 + 175 mm'))), has( wall cladding. bottom, lap), towards( lap, slab), equal( lap. size, 50 mm), or( and( has( wall cladding. bottom, offset), is( offset, horizontal), greater than equal( offset. size, 6 mm), is( wall cladding. type, direct fixed), prevent( offset, capillary action)), not( is( wall cladding. type, direct fixed))))))\n",
      "\n",
      "Source: G13AS2 3.3.1 All gully traps shall have (see Figures 2 and 3): Wastepipes that discharge to the gullytrap arranged to permit easy cleaning of the gullytrap.\n",
      "(40.42876528512046, 'if( exist( gully trap)), then( obligation( and( towards( wastepipe, gully trap), is( wastepipe. cleaning, easy))))')\n",
      "Target: if( towards( waste pipe, gully trap)), then( obligation( and( for( waste pipe. arrangement, easily cleaned), is( gully trap, easily cleaned))))\n",
      "\n",
      "Source: G13AS2 Drainage 3.3.1 All gully traps shall have (see Figures 2 and 3): The top of the water seal no more than 600 mm below the top of the gully dish.\n",
      "(57.825701954679644, \"if( exist( gully trap)), then( obligation( and( has( gully trap, water seal), has( gully trap, gully dish), less than equal( water seal. elevation, 'gully dish. elevation - 600 mm'))))\")\n",
      "Target: if( exist( gully trap)), then( obligation( and( define( top of( gully trap. gully dish), x0), greater than equal( top of( gully trap. water seal), 'x0 - 600 mm'))))\n",
      "\n",
      "Source: E2AS1 Metal cappings installed over parapets and enclosed balustrades. i) Where both ends of a capping are constrained, allowance shall be made for expansion.\n",
      "(70.23088617807946, 'if( and( is( capping. material, metal), has( capping, end), loop( for each( capping. end), is( capping. end, constrained)))), then( obligation( has( capping, expansion allowance)))')\n",
      "Target: if( and( is( capping. material, metal), above( capping. installation, and( parapet, balustrade)), is( balustrade, enclosed), loop( for each( capping. end), is( capping. end, constrained)))), then( obligation( has( capping, expansion allowance)))\n",
      "\n",
      "Source: CAS2 2.2.1 Fire safety system types, as defined in Table 2.2, shall be provided throughout firecells and be as specified in: Table 2.2d for risk group VP.\n",
      "(100.0, 'if( is( firecell. risk group, vp)), then( obligation( as per( firecell. fire safety system, nzbc cas2 t2.2.d)))')\n",
      "Target: if( is( firecell. risk group, vp)), then( obligation( as per( firecell. fire safety system, nzbc cas2 t2.2.d)))\n",
      "\n",
      "Source: E2AS1 The maximum moisture contents shall be: For reconstituted wood products, 18% at all times.\n",
      "(78.12312949601142, 'if( is( product. material, reconstituted wood)), then( obligation( less than equal( product. moisture content, 18 percent)))')\n",
      "Target: if( and( is( product. material, wood), is( wood. type, reconstituted))), then( obligation( less than equal( product. moisture content, 18 percent)))\n",
      "\n",
      "Source: E2AS1 10.3 Measuring moisture content 10.3.1 Timber; Measurement shall be by the recommended procedure in the Scion (New Zealand Forest Research Institute) publication 'Measurement of moisture content of Wood' using electrical resistance type moisture meters with insulated probes. Representative samplings of measurements shall be taken: a) With meters calibrated to AS/NZS 1080.1 Appendix E b) By inserting probes to at least 1/3 the depth of timber being measured, at a distance exceeding 200 mm from board ends c) Using correction factors for timber species, temperature, and treatment type (outlined in Scion publication above).\n",
      "(39.56362097866867, \"if( is( material, timber)), then( obligation( and( has( material, moisture content), as per( moisture content. measurement, scion publication), by( moisture content. measurement, electrical resistance type moisture meter), is( moisture meter. probe, insulated), greater than equal( moisture meter. probe depth, '1/3 * timber depth'), greater than( moisture meter. probe distance, 200 mm), comply with( moisture meter. calibration, as/nzs 1080.1 appendix e), apply correction factors( moisture content. measurement, timber species, temperature, treatment type))))\")\n",
      "Target: if( and( by( timber. moisture content, measurement))), then( obligation( and( is( measurement. recommended procedure, measurement of moisture content of wood), as per( measurement. recommended procedure, scion publication), by( measurement, moisture meter), is( moisture meter. type, electrical resistance), has( moisture meter, insulated probe), as per( moisture meter. calibration, nzs 1080 1 appendix e), by( measurement. sampling, probe), into( probe, timber), define( timber. depth, x0), greater than equal( probe. depth, '1/3 * x0'), has( timber, board), define( board. end, x1), greater than( probe. location, 'x1 + 200 mm'), include( measurement. correction factor, and( timber species, temperature, treatment type)), as per( measurement. correction factor, scion publication))))\n"
     ]
    }
   ],
   "source": [
    "dfs = [pd.read_csv('eppm_preds/context_full_perclause_reverse_71.txt', sep=';;;', header=None)]\n",
    "valid_df.reset_index(drop=True, inplace=True)\n",
    "# Use self reflection functionality for scoring the predictions\n",
    "print(get_self_reflection_samples(valid_df, dfs, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Step                                                                  35.00\n",
       "context_no_perclause_reversed_gpt4_doc_test_55 - num_samples          32.35\n",
       "context_full_perclause_reversed_gpt4_6000_test_71 - num_samples       39.61\n",
       "context_full_perclause_reversed_gpt4_6000_doc_test_55 - num_samples   43.02\n",
       "context_full_perclause_reversed_gpt4_8000_71 - num_samples            55.13\n",
       "context_full_perclause_reversed_gpt4_6000_71 - num_samples            39.77\n",
       "context_full_perclause_reversed_gpt4_doc_test_55 - num_samples        26.47\n",
       "context_full_perclause_reversed_gpt4_test_71 - num_samples            25.01\n",
       "context_full_perclause_reversed_gpt4_71 - num_samples                 25.01\n",
       "context_no_perclause_reversed_gpt4_71 - num_samples                   30.37\n",
       "context_intro_perclause_reversed_gpt4_71 - num_samples                30.10\n",
       "context_no_perclause_reversed_gpt4_test_71 - num_samples              30.44\n",
       "context_full_CoT_align_stepbystep_perclause_6000_71 - num_samples     38.99\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "df = pd.read_csv('data/eppm_num_samples.csv')\n",
    "\n",
    "df = df[[col for col in df.columns if not col.endswith('MIN') and not col.endswith('MAX')]]\n",
    "\n",
    "# Average all values per column\n",
    "column_averages = df.mean()\n",
    "\n",
    "column_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lrml_inference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "682ce8d48ddc5f7f5326e7d113970954036486eb8c97c20cb684e47a3e8d815d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
